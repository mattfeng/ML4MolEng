{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPcC1SXoUTmPIGKIFUNrSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwang2/ML4MolEng/blob/master/recitations/pytorch_autograd_tutorial_0323.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tlA4mWBsznU"
      },
      "source": [
        "# Automatic Differentiation \n",
        "\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIwBEcdDtbTX"
      },
      "source": [
        "import numpy as np "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGTH5DMx1nSK",
        "outputId": "65953f6e-f4f0-4c81-f5cc-eb8b3aebde75"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Mar 23 20:46:41 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1croSx_2ZVb",
        "outputId": "bb3c0d70-7b69-43df-c9b5-08048c3d25f9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Mar 23 20:49:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    33W / 250W |    897MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JojpnJT1vDs"
      },
      "source": [
        "tensor = torch.randn(10, 10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB0ktYN214sQ",
        "outputId": "8f09d182-ad08-4183-8fae-76f1810653dd"
      },
      "source": [
        "tensor"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.7804e-01, -1.2524e+00,  1.2423e+00, -6.1221e-01, -9.6743e-01,\n",
              "         -3.9595e-02, -4.6425e-01, -1.0883e+00,  2.2366e-01,  1.0789e-01],\n",
              "        [-2.4428e-01,  3.4090e-01,  7.8786e-01, -1.2474e+00,  2.0469e-03,\n",
              "          1.2347e-02, -1.7928e-01,  3.7510e-01, -6.4942e-01,  1.9122e+00],\n",
              "        [ 1.0504e+00,  9.9985e-01, -7.3889e-01,  4.2577e-01,  3.2218e-01,\n",
              "         -8.3960e-01,  1.7391e+00, -1.7051e-01,  7.8097e-02, -2.2363e-01],\n",
              "        [ 3.8184e-01,  2.9231e+00, -4.0160e-01, -1.0353e+00,  1.5898e+00,\n",
              "         -7.4578e-01, -8.9066e-01,  9.9021e-01, -1.9772e+00, -3.6795e-01],\n",
              "        [-1.2501e+00, -1.3084e+00, -1.3069e+00,  1.0536e-01, -7.1493e-01,\n",
              "         -5.7653e-01, -5.7896e-01,  9.3114e-01,  5.0298e-02, -7.5323e-01],\n",
              "        [ 6.2665e-01,  5.9188e-01,  2.5031e+00,  3.2000e-01,  1.0098e-01,\n",
              "         -1.5848e+00,  1.6171e-01, -1.6718e-01,  7.6725e-02,  6.1158e-01],\n",
              "        [ 1.6765e+00,  2.5081e+00,  6.8912e-02,  1.7477e-01, -1.1354e-01,\n",
              "         -1.7098e+00, -1.4019e+00,  9.5696e-01,  7.9686e-01,  1.3821e+00],\n",
              "        [-4.9582e-02,  2.0456e-01,  7.4422e-01, -2.1865e-01,  2.0732e-01,\n",
              "          7.9386e-01, -6.9231e-01,  7.1460e-01, -5.7249e-01, -2.8200e-01],\n",
              "        [ 1.0022e+00,  1.2287e+00, -8.8851e-01,  5.1324e-01,  2.0585e-01,\n",
              "          1.2677e+00, -3.5245e-01, -1.4882e+00, -1.5204e+00,  2.4612e+00],\n",
              "        [-2.3459e+00, -2.0208e+00,  1.3743e+00, -6.6870e-01, -3.3722e-01,\n",
              "         -2.1129e-01, -1.0422e+00,  5.8428e-01,  1.3720e+00, -7.6995e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vUNTP5u1z8V"
      },
      "source": [
        "gputensor = tensor.to(0) # 0: gpu id "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZrzlBmj10-R",
        "outputId": "172f3e7c-0b81-4e63-b946-8bb10ec9ffe8"
      },
      "source": [
        "gputensor.sum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.6379, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xXljg-Et8dn"
      },
      "source": [
        "# from numpy to torch.Tensor "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqUsRUQGtfAK"
      },
      "source": [
        "junk = np.ones(100) # float 64 a"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlvOLEgtosm",
        "outputId": "bb5f98a0-f005-4ffc-f417-ef392b9c8f8d"
      },
      "source": [
        "junk"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26gx9z8Ltgnl"
      },
      "source": [
        "mytensor = torch.Tensor(junk) # produce a float32 tensor "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-74yiEC-tkfV"
      },
      "source": [
        "mydoubletensor = torch.DoubleTensor(junk) # produce a float64 tensor "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnCuZRrtt0VQ"
      },
      "source": [
        "# indexing in numpy "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0WOBdknuCJd",
        "outputId": "daf565a8-5988-4227-d0b1-e3d005fe70eb"
      },
      "source": [
        "junk[4]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw6abGMauG16",
        "outputId": "b68e9da3-b70f-4d56-a7cc-eca0a8f0981e"
      },
      "source": [
        "junk[[1, 3, 10]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2FesK7quK4g"
      },
      "source": [
        "# indexing in torch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRb7NipxuOvL",
        "outputId": "4dd3212c-feff-435a-9d23-2048c74da9cf"
      },
      "source": [
        "mytensor[[1, 3, 6]]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M37Wun5uQat"
      },
      "source": [
        "newtensor = torch.randn(10, 10, 5) # generate a 3D tensor"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSKkBh7RufLE",
        "outputId": "3b62be5e-8bc5-4dd9-faf9-8ec9bd702723"
      },
      "source": [
        "newtensor[:, [1,5,7], :].shape # (10, 3, 5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luc_Y0aLuuto",
        "outputId": "05e2ea93-b488-4464-d207-dfb437245057"
      },
      "source": [
        "newtensor.numpy()[:, [1,5,7], :].shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 3, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTM23XaRu3Iy"
      },
      "source": [
        "# Automatic Differentiation (backwardpropation is a special case for Automatic Differnertiation )\n",
        "\n",
        "# cache your computation in a graph, and trace the gradient calculation backward from your output \n",
        "\n",
        "\n",
        "# computation: y = G( f(x) + h( g(x) ) )^-1 + sigmoid( W x + b ) \n",
        "\n",
        "# Forward calcualtion \n",
        "# Pytorch first caches your computation as a graph \n",
        "\n",
        "# x \n",
        "# x2= f(x) , x3 =g(x)\n",
        "# x4 = h(x3) \n",
        "# y = x2 + x4 \n",
        "\n",
        "\n",
        "# Backward calculation \n",
        "\n",
        "# Computation Gradients dy/dx  (e.g. when trainign MLP dL/dW) \n",
        "\n",
        "# push gradient calc from y all the way back to x \n",
        "\n",
        "# dy/dy = 1\n",
        "# dy/dx2 = dy/dy dy/dx2 = 1\n",
        "# dy/dx4 = dy/dy dy/dx4 = 1\n",
        "\n",
        "# more chain rules \n",
        "\n",
        "# dy/dx3 = dy/dx4 dx4/dx3 = dy/dx4 dh/x3 \n",
        "# dy/dx = dy/dx2 dx2/dx = dy/dx2 df/dx \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzZ3pm7TzpI-"
      },
      "source": [
        "\n",
        "x = torch.randn(100, 100)\n",
        "x.requires_grad = True \n",
        "y = torch.exp(- ( x**2 + torch.exp(-x) * 100) ).sum() # how to write a function \n",
        "y.backward() #"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzozcvGhz83_",
        "outputId": "60eacaed-4b7d-4c79-cf0f-97ce1213e957"
      },
      "source": [
        "x.grad # dy/dx "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 8.1804e-34,\n",
              "         1.6507e-14],\n",
              "        [0.0000e+00, 0.0000e+00, 1.7389e-26,  ..., 8.3700e-10, 0.0000e+00,\n",
              "         5.7033e-43],\n",
              "        [7.2324e-24, 7.7323e-07, 8.2487e-25,  ..., 0.0000e+00, 1.8772e-36,\n",
              "         3.7210e-41],\n",
              "        ...,\n",
              "        [0.0000e+00, 2.0327e-34, 0.0000e+00,  ..., 3.8816e-29, 8.3470e-35,\n",
              "         2.6122e-29],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9659e-24, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [7.5878e-32, 9.8497e-42, 2.5993e-18,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0qKzuayz-n2"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}