{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wc_fzIDFu27D",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#  <center> Problem Set 4 <center>\n",
    "<center> Spring 2021 <center>\n",
    "<center> 3.100/3.322, 10.402/10.602, 20.301/20.401 <center>\n",
    "<center> Due:10 pm ET on Thursday, Apr 22, 2021 <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "D86KaQiJu27R",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Part 1. Graph Convolutional Nets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "J9egPqYGu27S",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 1.1 Install and try out RDkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hUVPzIPKvxPf",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "First, request a GPU by going to Edit/Notebook Settings/Hardware Accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaqogUbau27S",
    "outputId": "72230ac4-73d3-43c2-cfb6-f4d8a5e95bb9"
   },
   "outputs": [],
   "source": [
    "# This is a hack to install RDkit without needing to install conda which might take minutes.\n",
    "# If you have Anaconda installed, you can install rdkit from Anaconda:\n",
    "#     conda install rdkit -c conda-forge\n",
    "\n",
    "# url = 'https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
    "# !curl -L $url | tar xj lib\n",
    "# !mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.7/dist-packages/\n",
    "\n",
    "# x86 = '/usr/lib/x86_64-linux-gnu'\n",
    "# !mv lib/*.so.* $x86/\n",
    "# !ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Kh0SNwnEu27T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Descriptors,Crippen\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from rdkit import RDLogger   \n",
    "RDLogger.DisableLog('rdApp.*') # turn off RDKit warning message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jrooBdScu27T"
   },
   "outputs": [],
   "source": [
    "# Optional: mount your google drive to save model and files \n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# mydrive = '/content/drive/MyDrive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "The following example creates **dopamine** and **caffeine** from a SMILES string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qgZjTmmeu27T"
   },
   "outputs": [],
   "source": [
    "# make a mol object \n",
    "dopamine_mol = Chem.MolFromSmiles(\"C1=CC(=C(C=C1CCN)O)O\") # Dopamine \n",
    "caffeine_mol = Chem.MolFromSmiles(\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\") # Caffeine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Create four more molecules from their SMILES string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "################ Code #################\n",
    "\n",
    "lsd_mol = Chem.MolFromSmiles(\"CCN(CC)C(=O)C1CN(C2CC3=CNC4=CC=CC(=C34)C2=C1)C\")\n",
    "cocaine_mol = Chem.MolFromSmiles(\"CN1C2CCC1C(C(C2)OC(=O)C3=CC=CC=C3)C(=O)OC\")\n",
    "acetaminophen_mol = Chem.MolFromSmiles(\"CC(=O)Nc1ccc(cc1)O\")\n",
    "ibuprofen_mol = Chem.MolFromSmiles(\"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\")\n",
    "pethidine_mol = Chem.MolFromSmiles(\"CCOC(=O)C1(CCN(CC1)C)C2=CC=CC=C2\")\n",
    "delta9_thc_mol = Chem.MolFromSmiles(\"CCCCCC1=CC(=C2C3C=C(CCC3C(OC2=C1)(C)C)C)O\")\n",
    "\n",
    "################ Code #################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Visualize the molecules using RDkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4__JJvjju27U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ Code #################\n",
    "\n",
    "Draw.MolsToGridImage([\n",
    "    dopamine_mol,\n",
    "    caffeine_mol,\n",
    "    lsd_mol,\n",
    "    cocaine_mol,\n",
    "    acetaminophen_mol,\n",
    "    ibuprofen_mol,\n",
    "    pethidine_mol,\n",
    "    delta9_thc_mol\n",
    "])\n",
    "\n",
    "################ Code #################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6vuVsOhYu27U",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 1.2 Construct molecular graph datasets and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ADhhYCE6dVsF"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps4/data/qm9.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Helper functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nq0h_UJxu27V"
   },
   "outputs": [],
   "source": [
    "# implement SMILES to graph function  \n",
    "def smiles2graph(smiles):\n",
    "    \"\"\"\n",
    "    Transfrom smiles into a list nodes (atomic number)\n",
    "    \n",
    "    Args: \n",
    "        smiles (str): SMILES strings\n",
    "    \n",
    "    Return: \n",
    "        z(np.array), A (np.array): list of atomic numbers, adjacency matrix \n",
    "    \"\"\"\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles) # no hydrogen \n",
    "    z = np.array([atom.GetAtomicNum() for atom in mol.GetAtoms()])\n",
    "    A = np.stack(Chem.GetAdjacencyMatrix(mol))\n",
    "    \n",
    "    return z, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YVSxuShzu27W"
   },
   "outputs": [],
   "source": [
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 AtomicNum_list,\n",
    "                 Edge_list,\n",
    "                 Natom_list,\n",
    "                 y_list):\n",
    "        \"\"\"\n",
    "        Represents a dataset of molecular graphs.\n",
    "        \n",
    "        Args: \n",
    "            z_list (list of torch.LongTensor)\n",
    "            a_list (list of torch.LongTensor)\n",
    "            N_list (list of int)\n",
    "            y_list (list of torch.FloatTensor)\n",
    "        \"\"\"\n",
    "        self.AtomicNum_list = AtomicNum_list # atomic number\n",
    "        self.Edge_list = Edge_list           # edge list \n",
    "        self.Natom_list = Natom_list         # Number of atoms \n",
    "        self.y_list = y_list                 # properties to predict \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Natom_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        AtomicNum = torch.LongTensor(self.AtomicNum_list[idx])\n",
    "        Edge = torch.LongTensor(self.Edge_list[idx])\n",
    "        Natom = self.Natom_list[idx]\n",
    "        y = torch.Tensor(self.y_list[idx])\n",
    "        \n",
    "        return AtomicNum, Edge, Natom, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0lPCLjWpu27X"
   },
   "outputs": [],
   "source": [
    "def collate_graphs(batch):\n",
    "    \"\"\"\n",
    "    Batch multiple graphs into one batched graph.\n",
    "    \n",
    "    Args:\n",
    "        batch (tuple): tuples of AtomicNum, Edge, Natom and y obtained from\n",
    "            GraphDataset.__getitem__() \n",
    "        \n",
    "    Return \n",
    "        (tuple): Batched AtomicNum, Edge, Natom, y\n",
    "    \"\"\"\n",
    "    \n",
    "    AtomicNum_batch = []\n",
    "    Edge_batch = []\n",
    "    Natom_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    cumulative_atoms = np.cumsum([0] + [b[2] for b in batch])[:-1]\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        z, a, N, y = batch[i]\n",
    "        index_shift = cumulative_atoms[i]\n",
    "        a = a + index_shift\n",
    "        AtomicNum_batch.append(z) \n",
    "        Edge_batch.append(a)\n",
    "        Natom_batch.append(N)\n",
    "        y_batch.append(y)\n",
    "        \n",
    "    AtomicNum_batch = torch.cat(AtomicNum_batch)\n",
    "    Edge_batch = torch.cat(Edge_batch, dim=1)\n",
    "    # edit: should NOT be sum\n",
    "    Natom_batch = Natom_batch\n",
    "    y_batch = torch.cat(y_batch)\n",
    "    \n",
    "    return AtomicNum_batch, Edge_batch, Natom_batch, y_batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Example usage of `collate_graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sDVilSwqdVsI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 6, 7, 6, 6, 8]),\n",
       " tensor([[0, 2, 2, 1, 3, 5, 5, 4],\n",
       "         [2, 0, 1, 2, 5, 3, 4, 5]]),\n",
       " 6,\n",
       " tensor([74.1800, 64.3200]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define graph 1 \n",
    "AtomicNum1 = torch.LongTensor([6, 6, 7])\n",
    "Edge1  = torch.LongTensor([\n",
    "    [0, 2, 2, 1],\n",
    "    [2, 0, 1, 2]\n",
    "    ])\n",
    "Natom1 = 3\n",
    "y1     = torch.Tensor([74.18])\n",
    "\n",
    "# define graph 2 \n",
    "AtomicNum2 = torch.LongTensor([6, 6, 8])\n",
    "Edge2  = torch.LongTensor([\n",
    "    [0, 2, 2, 1], \n",
    "    [2, 0, 1, 2]\n",
    "    ])\n",
    "Natom2 = 3\n",
    "y2     = torch.Tensor([64.32])\n",
    "\n",
    "graph1 = (AtomicNum1, Edge1, Natom1, y1)\n",
    "graph2 = (AtomicNum2, Edge2, Natom2, y2)\n",
    "\n",
    "collate_graphs((graph1, graph2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3f3sGR1XdVsJ",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**a.** Write the code to make lists of data for molecular graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv(\"./data/qm9.csv\", index_col=0)\n",
    "df = shuffle(df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>smiles</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>...</th>\n",
       "      <th>zpve</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0_atom</th>\n",
       "      <th>u298_atom</th>\n",
       "      <th>h298_atom</th>\n",
       "      <th>g298_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133347</td>\n",
       "      <td>N=C1ONC(F)CC1N</td>\n",
       "      <td>3.21895</td>\n",
       "      <td>1.39847</td>\n",
       "      <td>0.97492</td>\n",
       "      <td>4.3260</td>\n",
       "      <td>67.62</td>\n",
       "      <td>-0.2237</td>\n",
       "      <td>-0.0530</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088674</td>\n",
       "      <td>-494.021522</td>\n",
       "      <td>-494.013781</td>\n",
       "      <td>-494.012837</td>\n",
       "      <td>-494.054037</td>\n",
       "      <td>28.814</td>\n",
       "      <td>-1316.796261</td>\n",
       "      <td>-1323.492410</td>\n",
       "      <td>-1330.603342</td>\n",
       "      <td>-1226.964583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104249</td>\n",
       "      <td>C#CC1OCC1(C)CC</td>\n",
       "      <td>2.16265</td>\n",
       "      <td>1.30083</td>\n",
       "      <td>1.08209</td>\n",
       "      <td>2.0126</td>\n",
       "      <td>84.42</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179734</td>\n",
       "      <td>-387.041271</td>\n",
       "      <td>-387.031192</td>\n",
       "      <td>-387.030248</td>\n",
       "      <td>-387.076444</td>\n",
       "      <td>37.251</td>\n",
       "      <td>-2007.551893</td>\n",
       "      <td>-2019.891858</td>\n",
       "      <td>-2031.746758</td>\n",
       "      <td>-1866.997407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65348</td>\n",
       "      <td>C#CC1(C)CN1C1CC1</td>\n",
       "      <td>3.01219</td>\n",
       "      <td>1.02849</td>\n",
       "      <td>0.99222</td>\n",
       "      <td>1.4406</td>\n",
       "      <td>87.74</td>\n",
       "      <td>-0.2305</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>-365.931722</td>\n",
       "      <td>-365.922230</td>\n",
       "      <td>-365.921286</td>\n",
       "      <td>-365.966064</td>\n",
       "      <td>36.071</td>\n",
       "      <td>-1926.880591</td>\n",
       "      <td>-1938.700351</td>\n",
       "      <td>-1949.962255</td>\n",
       "      <td>-1792.438043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23752</td>\n",
       "      <td>OC1CCCNC1F</td>\n",
       "      <td>3.42107</td>\n",
       "      <td>2.33187</td>\n",
       "      <td>1.38668</td>\n",
       "      <td>1.6829</td>\n",
       "      <td>59.07</td>\n",
       "      <td>-0.2374</td>\n",
       "      <td>-0.0261</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085355</td>\n",
       "      <td>-422.688923</td>\n",
       "      <td>-422.682912</td>\n",
       "      <td>-422.681967</td>\n",
       "      <td>-422.718980</td>\n",
       "      <td>23.263</td>\n",
       "      <td>-1309.486409</td>\n",
       "      <td>-1316.380223</td>\n",
       "      <td>-1322.898159</td>\n",
       "      <td>-1227.855645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97187</td>\n",
       "      <td>CN=C1COCC(=N)N1</td>\n",
       "      <td>2.69462</td>\n",
       "      <td>1.34868</td>\n",
       "      <td>0.92725</td>\n",
       "      <td>1.9439</td>\n",
       "      <td>78.94</td>\n",
       "      <td>-0.2412</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148950</td>\n",
       "      <td>-435.278839</td>\n",
       "      <td>-435.270248</td>\n",
       "      <td>-435.269304</td>\n",
       "      <td>-435.312435</td>\n",
       "      <td>31.733</td>\n",
       "      <td>-1710.815437</td>\n",
       "      <td>-1721.421594</td>\n",
       "      <td>-1731.497506</td>\n",
       "      <td>-1588.403492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133880</th>\n",
       "      <td>70750</td>\n",
       "      <td>CC12COCCCC1N2</td>\n",
       "      <td>2.39837</td>\n",
       "      <td>1.58044</td>\n",
       "      <td>1.17215</td>\n",
       "      <td>1.7948</td>\n",
       "      <td>81.38</td>\n",
       "      <td>-0.2326</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.3114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>-404.332160</td>\n",
       "      <td>-404.323768</td>\n",
       "      <td>-404.322824</td>\n",
       "      <td>-404.364570</td>\n",
       "      <td>33.673</td>\n",
       "      <td>-2041.140567</td>\n",
       "      <td>-2055.427065</td>\n",
       "      <td>-2067.874961</td>\n",
       "      <td>-1891.858686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133881</th>\n",
       "      <td>83730</td>\n",
       "      <td>N=C1OC2COC2C1O</td>\n",
       "      <td>2.66475</td>\n",
       "      <td>1.77836</td>\n",
       "      <td>1.29694</td>\n",
       "      <td>3.3532</td>\n",
       "      <td>65.23</td>\n",
       "      <td>-0.2639</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>-475.009780</td>\n",
       "      <td>-475.002370</td>\n",
       "      <td>-475.001426</td>\n",
       "      <td>-475.041841</td>\n",
       "      <td>28.242</td>\n",
       "      <td>-1566.520370</td>\n",
       "      <td>-1576.090510</td>\n",
       "      <td>-1584.980430</td>\n",
       "      <td>-1456.620326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133882</th>\n",
       "      <td>68750</td>\n",
       "      <td>CC12COC(=O)C1(C)C2</td>\n",
       "      <td>2.46505</td>\n",
       "      <td>1.70310</td>\n",
       "      <td>1.22714</td>\n",
       "      <td>4.5140</td>\n",
       "      <td>75.26</td>\n",
       "      <td>-0.2577</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158933</td>\n",
       "      <td>-423.074783</td>\n",
       "      <td>-423.066080</td>\n",
       "      <td>-423.065135</td>\n",
       "      <td>-423.107724</td>\n",
       "      <td>32.904</td>\n",
       "      <td>-1892.247742</td>\n",
       "      <td>-1903.673426</td>\n",
       "      <td>-1914.341706</td>\n",
       "      <td>-1763.407594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133883</th>\n",
       "      <td>30336</td>\n",
       "      <td>CC1CCC2CCCN21</td>\n",
       "      <td>2.85286</td>\n",
       "      <td>1.67277</td>\n",
       "      <td>1.10788</td>\n",
       "      <td>2.2479</td>\n",
       "      <td>85.96</td>\n",
       "      <td>-0.1906</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174291</td>\n",
       "      <td>-366.070460</td>\n",
       "      <td>-366.062757</td>\n",
       "      <td>-366.061812</td>\n",
       "      <td>-366.102491</td>\n",
       "      <td>30.751</td>\n",
       "      <td>-2013.939935</td>\n",
       "      <td>-2026.882308</td>\n",
       "      <td>-2038.143584</td>\n",
       "      <td>-1878.047213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133884</th>\n",
       "      <td>82554</td>\n",
       "      <td>CC1C2CC3(CCC13)C2</td>\n",
       "      <td>2.64698</td>\n",
       "      <td>1.66358</td>\n",
       "      <td>1.31018</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>89.78</td>\n",
       "      <td>-0.2544</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208642</td>\n",
       "      <td>-351.116410</td>\n",
       "      <td>-351.108827</td>\n",
       "      <td>-351.107883</td>\n",
       "      <td>-351.147795</td>\n",
       "      <td>32.418</td>\n",
       "      <td>-2191.035525</td>\n",
       "      <td>-2206.719485</td>\n",
       "      <td>-2219.760377</td>\n",
       "      <td>-2034.989097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133885 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index              smiles        A        B        C      mu  alpha  \\\n",
       "0       133347      N=C1ONC(F)CC1N  3.21895  1.39847  0.97492  4.3260  67.62   \n",
       "1       104249      C#CC1OCC1(C)CC  2.16265  1.30083  1.08209  2.0126  84.42   \n",
       "2        65348    C#CC1(C)CN1C1CC1  3.01219  1.02849  0.99222  1.4406  87.74   \n",
       "3        23752          OC1CCCNC1F  3.42107  2.33187  1.38668  1.6829  59.07   \n",
       "4        97187     CN=C1COCC(=N)N1  2.69462  1.34868  0.92725  1.9439  78.94   \n",
       "...        ...                 ...      ...      ...      ...     ...    ...   \n",
       "133880   70750       CC12COCCCC1N2  2.39837  1.58044  1.17215  1.7948  81.38   \n",
       "133881   83730      N=C1OC2COC2C1O  2.66475  1.77836  1.29694  3.3532  65.23   \n",
       "133882   68750  CC12COC(=O)C1(C)C2  2.46505  1.70310  1.22714  4.5140  75.26   \n",
       "133883   30336       CC1CCC2CCCN21  2.85286  1.67277  1.10788  2.2479  85.96   \n",
       "133884   82554   CC1C2CC3(CCC13)C2  2.64698  1.66358  1.31018  0.0732  89.78   \n",
       "\n",
       "          homo    lumo     gap  ...      zpve          u0        u298  \\\n",
       "0      -0.2237 -0.0530  0.1707  ...  0.088674 -494.021522 -494.013781   \n",
       "1      -0.2491  0.0210  0.2701  ...  0.179734 -387.041271 -387.031192   \n",
       "2      -0.2305  0.0452  0.2756  ...  0.168280 -365.931722 -365.922230   \n",
       "3      -0.2374 -0.0261  0.2113  ...  0.085355 -422.688923 -422.682912   \n",
       "4      -0.2412 -0.0095  0.2318  ...  0.148950 -435.278839 -435.270248   \n",
       "...        ...     ...     ...  ...       ...         ...         ...   \n",
       "133880 -0.2326  0.0788  0.3114  ...  0.196344 -404.332160 -404.323768   \n",
       "133881 -0.2639  0.0099  0.2738  ...  0.125418 -475.009780 -475.002370   \n",
       "133882 -0.2577  0.0149  0.2726  ...  0.158933 -423.074783 -423.066080   \n",
       "133883 -0.1906  0.0534  0.2440  ...  0.174291 -366.070460 -366.062757   \n",
       "133884 -0.2544  0.0949  0.3493  ...  0.208642 -351.116410 -351.108827   \n",
       "\n",
       "              h298        g298      cv      u0_atom    u298_atom    h298_atom  \\\n",
       "0      -494.012837 -494.054037  28.814 -1316.796261 -1323.492410 -1330.603342   \n",
       "1      -387.030248 -387.076444  37.251 -2007.551893 -2019.891858 -2031.746758   \n",
       "2      -365.921286 -365.966064  36.071 -1926.880591 -1938.700351 -1949.962255   \n",
       "3      -422.681967 -422.718980  23.263 -1309.486409 -1316.380223 -1322.898159   \n",
       "4      -435.269304 -435.312435  31.733 -1710.815437 -1721.421594 -1731.497506   \n",
       "...            ...         ...     ...          ...          ...          ...   \n",
       "133880 -404.322824 -404.364570  33.673 -2041.140567 -2055.427065 -2067.874961   \n",
       "133881 -475.001426 -475.041841  28.242 -1566.520370 -1576.090510 -1584.980430   \n",
       "133882 -423.065135 -423.107724  32.904 -1892.247742 -1903.673426 -1914.341706   \n",
       "133883 -366.061812 -366.102491  30.751 -2013.939935 -2026.882308 -2038.143584   \n",
       "133884 -351.107883 -351.147795  32.418 -2191.035525 -2206.719485 -2219.760377   \n",
       "\n",
       "          g298_atom  \n",
       "0      -1226.964583  \n",
       "1      -1866.997407  \n",
       "2      -1792.438043  \n",
       "3      -1227.855645  \n",
       "4      -1588.403492  \n",
       "...             ...  \n",
       "133880 -1891.858686  \n",
       "133881 -1456.620326  \n",
       "133882 -1763.407594  \n",
       "133883 -1878.047213  \n",
       "133884 -2034.989097  \n",
       "\n",
       "[133885 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QplWbt60dVsJ"
   },
   "outputs": [],
   "source": [
    "################ Code #################\n",
    "\n",
    "atomic_num_list = []\n",
    "edge_list = []\n",
    "y_list = []\n",
    "natom_list = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    smiles = row.smiles\n",
    "    atoms, adj = smiles2graph(smiles)\n",
    "    edges = torch.LongTensor(np.array(np.nonzero(adj)))\n",
    "    natom = len(atoms)\n",
    "    alpha = row.alpha\n",
    "    \n",
    "    atomic_num_list.append(atoms)\n",
    "    edge_list.append(edges)\n",
    "    # note we're adding a list; this is needed to convert it to a Tensor.\n",
    "    # see the example above for collate_graph\n",
    "    y_list.append([alpha])\n",
    "    natom_list.append(natom)\n",
    "    \n",
    "################ Code #################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t6uT_hHKdVsJ",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**b.** Write the code that will make train, validation, test datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YvrFsZMnu27Y"
   },
   "outputs": [],
   "source": [
    "################ Code #################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# notice how order changes; y_list is last\n",
    "data = list(zip(atomic_num_list, edge_list, natom_list, y_list))\n",
    "\n",
    "data_train_val, data_test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.8,\n",
    "    shuffle=True,\n",
    "    random_state=54321\n",
    "    )\n",
    "data_train, data_val = train_test_split(\n",
    "    data_train_val,\n",
    "    train_size=7/8,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "graphs_train = GraphDataset(*list(zip(*data_train)))\n",
    "graphs_val = GraphDataset(*list(zip(*data_val)))\n",
    "graphs_test = GraphDataset(*list(zip(*data_test)))\n",
    "\n",
    "train_loader = DataLoader(graphs_train, batch_size=512, shuffle=False, collate_fn=collate_graphs)\n",
    "val_loader = DataLoader(graphs_val, batch_size=512, shuffle=False, collate_fn=collate_graphs)\n",
    "test_loader = DataLoader(graphs_test, batch_size=512, shuffle=False, collate_fn=collate_graphs)\n",
    "\n",
    "################ Code #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 6, 8, 7, 6, 6, 7, 6, 6]),\n",
       " tensor([[0, 1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 7, 7, 7, 8, 8, 8],\n",
       "         [1, 0, 2, 3, 1, 1, 4, 8, 3, 5, 8, 4, 6, 7, 5, 7, 5, 6, 8, 3, 4, 7]]),\n",
       " 9,\n",
       " tensor([72.3100]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pND0eELru27Y",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 1.3 Complete the definition of a GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "07W6nUPkdVsK"
   },
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "def scatter_add(src, index, dim_size, dim=-1, fill_value=0):\n",
    "    \"\"\"\n",
    "    Sums all values from the src tensor into out at the indices specified in the index \n",
    "    tensor along a given axis dim. \n",
    "    \"\"\"\n",
    "    \n",
    "    # make index the same shape as src\n",
    "    # this will make `scatter_add_` add vectors from `src` to `out`\n",
    "    index_size = list(repeat(1, src.dim()))\n",
    "    index_size[dim] = src.size(dim)\n",
    "    index = index.view(index_size).expand_as(src)\n",
    "    \n",
    "    # create the shape of the out vector\n",
    "    # out will have shape src.size() but with `dim` changed to dim_size\n",
    "    # e.g.\n",
    "    #    - src contains 1 row vector for each edge,\n",
    "    #    - out's rows should have the same dim as those vectors,\n",
    "    #      but the number of rows should be the number of nodes,\n",
    "    #      not the number of edges\n",
    "    dim = range(src.dim())[dim] # convert -1 to actual dim number\n",
    "    out_size = list(src.size())\n",
    "    out_size[dim] = dim_size\n",
    "\n",
    "    out = src.new_full(out_size, fill_value)\n",
    "\n",
    "    return out.scatter_add_(dim, index, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0.0000,    0.0000,    0.0000,    0.0000],\n",
      "        [1000.0000,  500.0000,  250.0000,  125.0000],\n",
      "        [ 100.0000,   50.0000,   25.0000,   12.5000],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000],\n",
      "        [  10.0000,    5.0000,    2.5000,    1.2500],\n",
      "        [   0.0000,    0.0000,    0.0000,    0.0000]])\n"
     ]
    }
   ],
   "source": [
    "message_i2j = torch.Tensor(\n",
    "    [[1000., 500., 250., 125.],\n",
    "     [ 100.,  50.,  25., 12.5],\n",
    "     [  10.,   5.,  2.5, 1.25]])  # 3 x 4\n",
    "\n",
    "Edge = torch.LongTensor(\n",
    "    [[0, 0, 3],\n",
    "     [1, 2, 4]])      # 2 x 3 (always 2 x something)\n",
    "\n",
    "node_message = scatter_add(\n",
    "    src=message_i2j,\n",
    "    index=Edge[1],\n",
    "    dim=0,\n",
    "    dim_size=6       # 4 x 6\n",
    "    ) \n",
    "\n",
    "print(node_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FqVacAGkdVsL",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Example usage for `scatter_add()` and `torch.split()`"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAECCAIAAADcgVIZAAABSWlDQ1BJQ0MgUHJvZmlsZQAAKJFjYGASSSwoyGFhYGDIzSspCnJ3UoiIjFJgf8bAyMDLwM8gxiCemFxc4BgQ4ANUwgCjUcG3a0DVQHBZF2SWpIjRLBb2K6yTlcUmtrlu2YypHgVwpaQWJwPpP0CckVxQVMLAwJgCZCuXlxSA2B1AtkgR0FFA9hwQOx3C3gBiJ0HYR8BqQoKcgewbQLZAckYi0AzGF0C2ThKSeDoSG2ovCPC5uPr4KAQbmxgZuYS7E3AwqaAktaIERDvnF1QWZaZnlCg4AkMpVcEzL1lPR8HIwMiIgQEU5hDVn2+Aw5JRjAMh1raIgcFWkIGBZQVCzCeIgWGjLtAbQQgx5UcMDIKHGBj2GRUkFiXCHcD4jaU4zdgIwubezsDAOu3//8/hDAzsmgwMf6////97+///f5cxMDDfYmA48A0AJmtdSuasIYUAAAA4ZVhJZk1NACoAAAAIAAGHaQAEAAAAAQAAABoAAAAAAAKgAgAEAAAAAQAAAhmgAwAEAAAAAQAAAQIAAAAAooOr0QAAQABJREFUeAHtnQ+803W9/7+UdWaRZ5nBvCnMq8QsucwbXOaVYorJhJRJIoMwRlLM9MZ+Wp35JzmQyaFERzcvx8TOTJIZBktDlkXMhJhBMcNyQjcmVg6qy05Z7Nxu+ntuX87O/p3Dztm/73be34dyPt/P9/P39f189/68/35GvPHGG4pcgoAgIAgIAoJAGQi8qYy6UlUQEAQEAUFAEEghILRE1oEgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAgIAoJAuQgILSkXQakvCAgCgoAgILRE1oAgIAjUFYFkLOCy6EforJ2xuo5DOi8LAaElZcEnlQUBQaAcBJJRn9NidoWT+nJakboaQEBoiQZeggxBEBiuCIQ62qNWXzjoNrUMVwiaZd6nNMtEZB6CgCDQeAhYOsJhg0FJ+Btv6DLiXASEL8nFQ+4EAUGghgjoISRyNQUCQkvKeY3JZLKc6lJXEBAEBIEmQUBoydBeZCLi99hNhlNPNbrDQ2tBagkCgoAg0DwICC0Z/LtMhj1mo7U9ajAbW1qMRuHRBw+h1BAEBIEmQ0DruveXX375b3/7Wwb0M844493vfnfmtj6JZNLkDkadlkSH2Rc0CC2pz1uQXgUBQUBLCGiUlvzqV7/68Y9/zL9//OMf8+CCnEyePNlms9WNqOitTmdqUJFoXDHYjLq8AcqtICAICALDDgHN0RIYkW9+85svvvjilClTIBjvfe973/Wud2Vey29/+9sDBw7s379/2bJlH/rQh6677rq3v/3tmae1TcTj8YRiNImIq7awS2/NhEAiGo7GsWBJRhKKkoxGQqGYotMZzRa2aHG/0+5V3AGfQ76xRnjnI9544w3tjHPbtm2PPPLIv/zLv1xzzTXZJKRwhFCU73znO//zP/9z8803v+997yssUP2ciMdk6bQEEj5b9fuSHgSBpkQg6NRf8XB33tTGLtsd81oU/jd5lI5o2G3MKyC3WkRAQ7Rk3bp1e/fu/ehHP3rRRReVCNXjjz++Y8eOpUuXTps2rcQqFSuWDDgMjqgnAkmpWJvSkCAgCAgCjYmAVmRczzzzzLPPPovkCqFW6UjCvpx++umwMkajcezYsaVXrEBJRFxJRTTvFUBSmhAEBIHGR0ATNsF/+MMfHnjggYULF+YTkiM719145RTTmWeeaZpy5Y1de/KZYfC/9NJLJ0yYsGbNmr/+9a81fR3xaCxFSiQkXU1Rl84EAUFAmwhogpZ0dnaOGzeuQLS133vdwpV7RznXbHpi0xrnqL23zV3YdaAIjHAnaH3QtRR5VvGseCQUjsbiyUQshhWXyVjxDqRBQUAQEAQKEUhG/W672ajX6fRGs90TiGks6Eb9aQlMCVZb0IM88Lq3er37x7jWP3TDrKmTp8664f6vuUbvXb12eyGAb3vb26644gpsiPNaqMZtPOixXXT+OWee+s753+3piXY67Q6n2+MLY4WiKDGf02r3BNPpanQubQoCgsAwRSAecNqc/oS1PRAK+dutCZ/D6tbWT039aQn6dky2zjrrrLw1sn/7rp4x0+dM6M3WTZ45fVT3zu37ezOy/06cOBFPFOyJszOrkTY4g8njx149tG/3jm0buzpcFqNeiUWjibSTSSwceiYYS4rDSTWQlzYFgWGMQNTXHkjYvQGv02qx2Jxef4ct4evwxTQESf1179ASjIALIDly8GC3Mm7CmKwHY8aNUY4eIHtya1ZuOglrgq5lz549tdDA6/QGo9lgVCz5o+BcuOPepK6OtATvzhEjRqjj0kSMgHyI5F4QyEEANefhw4czWbJoM1DkJGKhYFSxemwZ9azBbre4XMFQ3O3UivdN/WkJkJ166qk5wKVuurtRtI9qyaYara3cpfOzc3trojLh2WuvvTZy5MjevNr/1dWekvA1It/jKmTLILGTJk3CqbNOLji1x196bAwEkGwHg0G2PoWLFnLCcpVFm/MiY5GoYnQgBMlc+lQkwFAkpihCS3pBqaCz5Pb0BWUivIq6wSGRuernId871Ur/hYrwQWJ0wJQJE2C327MN4f70pz/h0Xnw4MG77rrr/PPPx3FHKEql34C0N2gEWLQY8bP1QazNol2wYEG2fJtF+/zzz2cW7cc//vFaSBoGPYmaV0gkEoou12hUr9cpqWzNXPXnSzIymVxMijAhaZakJcWcFLtoZ9asWRaLhS3P0aNHjxw5QsCVn//856zO119/nRpNRmPY0GH/Bh82Z86cAhO4FEBoocjnApatW7dCUSAnXMXAkzxBoBYIwIjce++9+IT150nGosXKn4vPFk/kL37xi8RJqoMnci3AaLY+6k9LYCBYNwW4jh43rlXZdRBJakb7fnD/YWXMLLKLXjTCNufc9JVd4B//+AePoC6Zi936rl27+BVWizUijYGQ8Jmdd955N910E4Ks7PkWpvk+2d9hnsB+EELrcrkKy0iOIFBtBNCMQkguueSSQqPNwq5ZtMSz+NGPfoTnGYu2lCqFjTRPjl5vUJLE/8u6EomkotdnSb2yntUlWX9aQtBf9teFk580a3rrxu2b9y+foBKT5M6ndh0ddfHMDGnJrgILAsFAN5Cdqabf/OY3j0pfeY+OHz8OdYF9ydAYmGtWLbRHLclvdEY+lpGYGQyGlpaWvKZqfKsSEjw0oRCldw0t4fv0er1UEXJSOm5SsiIIqGz0zJkz4ZJLbxAGhUX79a9/nS9xWHMnJrNR8cViCcXSSzziKQc3o9lUOpjVLll/WgIBQGWye/dupDHZs9VNX7Zs0uUrl1w/5m7XpNOO7lx7W1f3xWvcU4taSbF/QSXAgstuYeA07Aii2DxpLCMhXqRKXVQyA3VBepsWr51oD+kbtGl0+sok0iK5gTus2FPiKL/nPe/JJyTECFi52rd97+FupWXUhKlzlt3dNmtMLlgIpt1u96pVq0SxWbGXIQ2VgAA6EiJTsPspICSHt3tXrO7avv+o0jpu0hzX8jsXTMhdswp7ICJiwJ2g7RvUB17CuBqniMFqNyvt/mDC4VCJSTzgDyuWjj7DrvrPRROxHRGMokNesWJFvrime8+621b6tu493NM6ZtLMZXcvXzChiIQLmdXatWvvuOOO6umWe3p6VAIDU6nSmMy/0B5eI8xKhq6oCf5l6cMVVfYlE7iM72rlypXs1/paTu68bdrcLmVmW9vii89Wju7tWrlyS3LOph/fP70QL9AmaP9Xv/rVvuqSEgSqiQBLDgsRFm3uB55etY+2zl/eNv+Clld2QVVemHD/MxvmjC4cC/z0Kaec8oUvfKHw0TDJSQSdZnvQ6Pa2241K1Odx+xLOYMRrTZHeaKfd6TO2h7y2PEJcU2w0QUuYscfj4eeYXfNgZ8+pix0dHQjK8vfpg21oqOX//ve/w7tAWjLUhQQ55GMOwC9+HgfDLSzRUHtLAYVKKE98nNx+85Tr98558sfLT0gAk9tvNM/dPn1T9P7pBT2B2Oc+9zli9RcVCRYUlwxBoFwEPvOZz3AWUZ7gQTny6DXmW3rufu7JxaoXGYt2ysK9c55+rncVZ3WLEBt+mi3j8GVNlGQs0O5u94WiCcVgtrnavR7bCXPgsNt0UadpYzxwgmnJAq6GyfrLuNTJ3nLLLfxKohzGbKP06fOzyPLC2LeO5klvectb/il9ZQ9blZWl6UtKH0PiueeeIwGzTzE8YLIJjMrHvPOd7+zHpK2vYUgUjl0f+9jH+rLSKd30e5+PZefpUkqdfhQ77A1xDsWvU2hJNmSSrhICaEqISYGoKq/97l1P7VIm3T09446su3jO1JbNu7YfUCYUxApHPMu2DO090ZLy2hk2tzqjvSNg7ygyX4s3+kZKD1rfSyu0hO3GnXfeCRfMBuRTn/pUjgCnH4QQbT344IP/93//d/nll2vNd0TlSJhFntgNWqKSFvVfpkCkfaRk0B5oEiBkBGUQG9Jc5GcAgJaQzrbHzzw6kUgmkz1H92/1rtzcfXHb4qn5j0/c08JvfvObfh5KtiBQSQTYteD2lCvdSrWfcndvmTAmQ0oURXc2kS22HnxFUQpoCeXZAA1vWpICjV+AzLHlqkFQKlcbl1ZoCWigBkeIj9UgRAU3EUw++qMo/AQ/9dRTqMRhnLGLvf/++5FxEWlYG5AONApo3jnpK6/Q73//e5W6qIIy9BmqlIxiGONDUVQ+hmJo3fPqZt3uXzFt2tqDinLauKuXP3n/4qImb6ni0JJQKJRVUZKCQBURYKtU2HryaLfS2npa9gMdzmM9/UW2QDKM2hLvPE0ZwmYPv3pptKQ/+9nP8M5BEpPdCxSa3SoCBqxpsvPrktYQLWH+/NSiXgMyzt+Fopx99tlQCMKSsIww4aUAW3hICOa/H/zgB+fNm6fu+tmtQE5Wr17dj1CnLsAOrtOiUrJjx46ppEX9l8X0yiuvDEhLxrnWf39699HD2zeuXXHlVYc3bFo+tVD3zsjAM29RDm64UloQqCIC/drc/+53v/v0pz/NZ65y8OyxSKgcPInG/fwHwBIqwo8h8gzYMuzZ2AVmdtj8DLKr5vfw4YcfxroBhXF9pdbaoiUqplAILsSsEBWuV1999dChQ/z84dsBHUbtzFOWTuYFXH/99bfffvuGDRtIZDIbPYGUDI6EC1vnzFxYWKiUMrcFCd3oCZNTRjBTZ00dc+WU21Z2zX/aXUxcwCqEQS6oLhmCQFUQKKoIbB3VSnS9P2d3mCQIX8uY1n6NkTg+dfHixXDwXDDuHG0KB08aOxeawS4/Q2NS0uH0xRf0pjfVPxp69ixLTEM/sNj85S9/iXcnV6GQEKKSCmtx0UXsCzmqHIkO3An65noJ/LVIS1Ss074fY1VV25e+9CUYlGuvvbboawC7G2+8sb29/f3vfz/CsaJlmiOTT4V1w5W3sLoPbN/+wmkXz0kTkvRUx1wwYVTPo/2JntnfZRPj5gBHZqFNBPg82bsUjo2w3y09hw8cVjLa92QqssV75/cjq6YRqMOY9JXdGgI0xGJp+nLin5deeol4X7D1PMIon99ceJc8MlPXCLDZwy+ehpAQ9Ai/aUxb4UWKF+rN5dcAxx2sG3DqpBbeEXUhJ9qlJb1AlfQXSvORj3zkoYceMplMTSxOhSGDP8M/n81INi7du7w33tLdNu7H7l4VyeEXcP8aM25Udqm+9C9+8QvUUX33khIEqoYAgheYaWxq8n4TdZNmTmq55anth284YRPcvX3zrp5xrgxpyRsRi/aGG27Iy+QWpodPnis7sCn5WOWgps6mMdibcMtWjKd8R1AmCExGRKbeZpu6FPZVm5wMISFqWd6ucYABAC+msNi1wqDUxRGnSWgJEM+dO5fzGdetW3frrbcOgHijP+LLxLw4j5aMmeOe4124esn1yp2LLx7V8ucXNq5esavl0jV9J4llTRsZK1u8+opWs4YjySZHgN9reAkiU+R7gI2e07a486oVS25uaZs/ruWVp7y3PdUyZ/3iYkJZhbgYwDSoRYtvI1Jxrjx8+aWGoiAiU8kMOkg0kdyqwZMwzU/LxnL+gVAVFdPltVypW/w6iRYIYcghJMnDWztXrO3atT9lszBm0sXz2+52T81166Q8RrA44qA+yXNBq9TYBmineWgJS4dAh21tbbyJJjZCZ4mwW4E1yTHYb51+/5Mbxq3wbrxl7uqjSsvZ4yYt+NqTbQuy7C371gCqPCwXRMbVh4ikqowAVATZC8G1clkT3eTlmza03rZ69fVXpWKoTJ2zftOds4oYi8BJbN68uVIfNfKfQltKpGFssLKZGDU6nxo8CWYlw8Rky8qqcVoRVI3JQhJyCInSvfWWK6/bSoyANXdeMKrnlafWrVg5d273E08vn5yrXUKgh7MdLRC+rMbfePPQEj4H3jd+fFg1oDhhK1TlD6Q+zbM+CDKPoQGLJufLHDPd/dD0k4YNIJYX38zy5cvrM3rpdVgigGz2Ax/4AIsWB/jcn8jRpaxaRGSYilR1ow3bQRdcDDX7FWGFrHIw2FKqCZThJMin2Dve8Q6Vf+GrzMjK+DDLiZzEVpjvOmenSE/d2zdux2MMQ//0z9rkyZOUg6YlOEYsn9wr1s4MG6EFFv+198VpKloCmpdddhkvGxNh1PVwKhl8mynBR8VqRjAKF8zCLX1qcL4InTG2rotqrvRxSsnmQ4DQ1JySwKIdlA4AHNj9IJWt1+4HO2N+2bny3oiq7c+QmV//+tc/+clP2KXB32A2xleZIyNL30B48hopegsNKBIRuXXOhuic7PIMjKsIE5cuhP4Y64NKcXLZ/Q6QbsJf2yVLlhBvatOmTfPnzx9g5g39CCUkgVcJRIbJef4WptjEkBKwK+SbpGJeaORixSVPEKgwAmxfUAhDTqAKn/zkJ/P05EU746cZwyRcAvhl1Nqixf6Yi4FljxyNS7a2H0rz05/+FLkZGhqK8dNfaE4GQ/PWt741uxFaKCRdWQWSGE4f3v/U6pVP6aYXV4hSGGcUrISzatUi2YS0hFXLJgjXRSRdYFoLFOvRBxHM4DP42FjQGGX193FCRVhV8Lzw73AkWvsm64Gc9FkfBPgw2f3AZ8CdDBzYAipCYAt4aJYrTmPU+uEPf4jIoT7jLrlXRFtQC668GvhZq+7G0BUIDBb5kUgEGqkWQ7GfEZGpjjL9fcuU33mz+SrfUcT5F8y//4k1c/qT46viCvqi5bzBVO+2CWkJYEFCZsyYwRFbX/nKV1jB1YOvvi0j7IIdhqLwcSKGZtZ4ZmHsyErCBJOx8TWSgIrIQaf1fVPSewYB1T1bDWzBQmUnxKIlwbplrRJPDkdubKuyFy1K0G9961v8wjaoEpSp4WXJlQGBBNKwzFFJqqwMv8sMgckumZ2e4N70/TlHjx7c3uW98aqFRzZtuCH/vJd06brQEq3EnM/GqzA9sK9iYXlysC7HGZ6II6j7ihZopkzWohojAAYZhppbNnSoE/GZR5eYp05sponLXBoXAVYpugHWLawzcR7RZhNbT120hNfLY6CxcyUSVxMrQdX3SLAPXBryTycq+o73r/jQ5Z2j1kQeX5DPBlEcqgxihL6t5U66OfkS0ETxjjM85IS4I0V0WUVfT8Nmwskyx6afZsO+Hxl4EQRYtCiHVf3wt7/9bdgRvtYi5dJZSK152txKUCaqUlBEfCpj0YfGkf1bdx0eM31W31mAEyaNU3peOHhYUYrQElqgbi0JCd01ZKSaPogHTMERL1iwwOfzIaYcsKA8FAQEAU0jgAsh5OR73/seYltND7TswSFLKDLHo5tXL1ly22YoR++1f+/BnhZCyvTe5/zFOQYj7Jys6t80My0BPXY9iFm/9rWvIZ2sPpjSgyAgCFQLAdSBeDuiBMUnvFp9aKBdNbAFcr+csUxY7JrZumvFwhu7tu7cs2fn1nXXL+l84eyZrplFmBLqonoZVIyAnL6GetPktARYsIJFo/Xkk08OFSKpJwgIAppAACU8FrTf+MY3NDGa6gyCWL/Y0RRY9I5ZsP6JRxaPOei9ce5VV829sfOVca5HNt0/qwgpUTCBo4XaS7ybn5ZgcodZIZJWBLLVefvSqiAgCNQCAWKWoATds2cPStBa9FePPlByYOoGPVBDkPUNQffeWcs3PP18jJ3xq7Hnn96wfNZ7c8OnpItSCzqEPLCvYq1S2qQlcZ/DZDK7gxVCAWN2q9WKM7wa+aBCrUozgoAgUGsEsCEmiitKUDw2at13rfpDPIURPzG1cC4eVJ+oSXBJXrp0aV1MN7VJSxS9wWQ0GvSDAnLAwviH8xygBywlDwUBQUDrCHC6BCeusjV8/fXXtT7WoY4PRS/CLvzGtm7dWmIblMRzmWPLay/dUkf4Zo6QKnGsNSw20mRzLHRMzQTBefbZZzGSw499yGPARPjcc88l7COn4Q4YomDIPUhFQUAQGCICxNDDca/EQ8vxQWHf/cQTT+AlXpcN+BAnOchqxEbCRBjhPL9+6D8G+NVCrgUVQYaPL51qYz3IripTXBv+JclEPJFIKjq93qAvIgOszFRV7nho52XFA06rM6i3ORFEOqzGqo2xMjOVVgSB5kaAOCUc1gtrwg8u33WzThZhF/FjCGzBRaQAZorzNbtqLjxIuAjHAgnBSBUSwlVjh5I82Osp40pGAx1Oq9mgG3HqO88885xzzjzznaeO0BvNNpc3FEvmDbQit1deeeWZZ57JeVmDbc1g90Uifpcx2mE7x2j3xQZbX8oLAoJARRH493//9ylTpkBOCLtS0Ya11RgenViifvWrX0WDctpppx06dIig9F6vl39Jk8PulqeEU6ovIQG1uvEliZDbalsbM06zOdzO1MG6Op2ShD+JRsKhoOcSf2AVf8wVZgDgjjkvCwfaIYSKY3zxSCTW02JUkvBQSoWHpq0VLKMRBLSPwCc+8QnONidUF4aa2h9tOSOETqTCWkybVk4j1a5bL1oS87V3Juwbo36HoXCKyajPYXW5fc6Qq8jTwvKDyeEoAbhjItUMJlRcMup3O10PPKdMWbox6HWYhI4MBnIpKwhUBYGRI0diIozGF00qtppV6UMaLRmBesm4ouGIwe4uRkgYus7k5FEkHCl5GoMqCHd84YUXwh0T/7GwInTDF4r35SfCXrvZPN8Xt6zaEQ13CiHpg0ZSgkCdEUCFgFkXStBjx47VeSjDvvt60RKdXpdMqdv7uZB2JatxmHJvdzDF+JpgI9Gb0fc3FvS6HS5/ipokYwG31XTR/wvpHOvCkaDHWnEuqa9bSQkCgsBQEMDdBCUosVWGUlnqVA6BetESs82q+D3uQLQIOUlEfC63X7HazJWbZ15LyB/hjrHILgyjZnL72k0ht9Pd4bSYr14bNS3bEgn7XOYKOrvkDUZuBQFBYMgIqBHBcetDHT3kRqRi+QjUS1+it3s7nTbn1ef7Ro83m0wGA6ptGIFEPB6LRF7q1k1Z5vfaq/rzDXc8a9asYudlmdydHQHLDbcmx8++b3en21LAjSQiQX8wGI4m9dicueyiPil/HUoLgsDQEcBEmFBdeI+hOGnQ87KGPnnN1KwXX6IoBntnJLp7Y4fDYtBhvhWNRKLReFJntLq8W/bFwl5bwU94xUGDO+b4NoSt+S2bXL6OGa06o82eR0iQenlsJsOFV7i9wWgsGvI6LBZ3KJFfX+4FAUGgpghwgi9+i/0pQWs6lGHbGX4u2r/uuuuuxx57rBrjJKqP0+nctWtXQeOHumaMbp227sXMg+P71s0b36K0jJ62tGv3q2r28X2rprWOXbTtWKaUJASBoSNw6L4pLS1TVvUtutymdreNV1pmdOWstle3LBrfMn7pd3/MShw9Y92Lx3OrNMYdXzffeJljxXMeVwy4kzLbkepDQ6B+fEmaeidj4YDP63G7+EF34lTu7vD6gpF4ESVKlYg9JsJwx11dXQXnZRmdnR02XTSmmnQlQh6r9YaAYl8XioY6nb3sis7sbrcnA75Q7UZcJSCGS7PJgF1v9kR6p5t325vdMH9jnU6nX+f2e6/6oMfnNUfcjvbwcF2L6nlZwWCwUAnaMO+zkQdaL30JupGoz+VwP/x8t6K0tI426FGOpHwVj3T3pLb+rk6f126sCbJwx4QD4rysFStW4MzY16fR6Q+qdzGf07E6Zl4VCngs+UqcBH63adfblMJHLq0jEA5GkoopM8q820x+YyTiPrcnZHAF29NOvUan1+Mze1xeR8RjbowJVHqUnJc1ffp0lKBf/vKX8T6pdPPS3kAI1IsvSYY9dldQ7+zacejYG5CQWCwai8XiieTxV/dt89oSPoe9b/M40AQq8mzJkiV//OMf+z0vK+xtD+oW+YoRkpCnPaBY7dZ8ClORYQ3vRhLhTpfNbNTrRozQEVnH6uwMJ/oQiYe8TqsJkw2d3mC2uf1QiN4rUzH10GixewInIvKE3aYRlzzwcs/zqy8cMULvuC/39sS+AStCt91Ct6nK6Xg+KmdK6/FOq05n7QwHscfQ6Swd0d4eB/jb72DSdXBmcqF/Uwfq8IYzXaktUplJpodisrp8kbxoIeGOju8mLW6PtXcbY3J5HPrnvR2BLKAGGFtTPkLM8I53vKOIErQpZ6upSQ1NNFZ2rR1Lx7bO3pgj+M1u89WuGa1jl+3uzaqevqS3hzcI/U9ceiwLMzmZxKF101rGt2UG05e/ZenEViVHp5J5JokyEUitAGX0tGVdWzjaZ8eWdcumjU5BfSjd7LFtS8e3tIyd3da1Zdu2jffNm9iitM7oUp/xtngpExet27Jtx45tXW0zxirK2KU7UmqE46++uKNtSosyfumWfS+++Oqx3Nt0iX2rpqjdbiP46raN1G5pGb8sXfuNNxhTS8vEGTOmzGjr2rhlRwmqiQEGw3iObVuUGtyMto07OMFo46rZqdCwSkZf8urG2aOVlvHz7tvC49RMeExGr77kON+Qkv8RncjMVamkMdP0PxXRl2Rm+PLLL/Mt/+AHP8jkSKIGCCg16KNYF1vmtY7voxWFJXYvG986b0tvfg1oCV2htVu2bBnyqt5uT/w9vmXe6NHztmQTvuMvblw6hfMxR09btTs7P6+m3A4VATBvSZGAvvrHdnetWrct/fv9IhpqZXzbvszDF1dNaWmdsiqVcWxb2+wZs+/re5YiAErrom1q4VfZFygTM1Xzb7tmtyo5phTHWYhKy7R1aVuLY6mmUs9L1W8PPBh1ZFkLK91ZhpakJtVLBdODh/Sw5DK0ZF9KEX9iZBkk3ji+bR6kdN6WUofYV7OeqcrSEmby3e9+FwVsPB6v56yGWd/1knEZzcZYKJAlmMhh1pLhQChmNPeJtXOeVutmwYIFLS0thedl6WwetyHodnaGYgjjIgGvy2oiqEoML8ZwyGNRouTYLWaT0WRxZOQp1RrkMGlXZzSalJeDHR3B6Al5jd7i9CAPQpwTR8nRMzbbldXkCScT4bSSQG/rCAQDbnMGJ4PRqMdxKVGC2CcZDoa6Wy12iy6tAkurwXCqHd1DfkaExvOMTCnTST+JgQcTCUV6Wiy2Pg2czuKwwaioV4IYQj2tPO4VYCl6ZKmtvY+VBIFGFQOuWZmcdEJnsphauqPRWG72cLsjsAoB9zARbuLzsrT2TutFS8wOtzW+2sqPb2cgFMa1BG1JDCeTUNDvddvNttVxu8dZY1qiOtCGQqF8OxCd2RPw2WKeS85555nnXHi1J5AwuzeG8S6xxjudZuP55MSNVrvLbk74HRaHhKSvwCo3t/vWzdOFb73ifIPeZLG7OnyZcwjiUaI1G4x5P6KZPuOhTki7yZgKPZ26bA9wmGuGFGSKFUmwjU0q3Y9d/c5Ts64rUtV50ltej19tb/rkfwcYDOQN+saRPVmt6I0GOJ/0hdsuT3M60xmyjhqNxxNKiyGflOC3ZaDB+Anzw6ymh1fyTW96E8HYORmdk26H18zrN9u62XEZnYGQzuNu77zhsdW5028ZPdHm2uJtt2d/ZLlFqnaH0yzcCXYgd999tz5lWtZ7GfGsjLfjT4k3pQmFsKIQ89Hm8Hw/bpx93w44FfV8LI/baje7PQG7v7pO+73DauK/OrPLH3V2hIPBUDAYCHYsfqC9Y5E/5DuxLPohDsmIx2ZbHTMt6vB6LWitASjcbl0cKAmoNI0YPXtdIN8MCi38UBbjyQZTZA5FsvoZOhHrepTUSQ15V4p8YhFZekN59ZvmFhPh4XBelnbeV91oSSoasMMbdHiTHFmCF0c6ziM2OfxSY9dSR4A4niwSiXBe1q233po7DJ3B3OtXgkCFn6yosSAEvcHutLpcgbBit+VWlruhIKDDDMvFfx4lHnRZr3igHRsrj8FkbOmJECRB6Ytewy4+yerRR3z+55Upq/w+l+lEf8loaUwJxdNcQFiBD+qTOw1l1L11Bh4MHAnrPJGIw0v01sCesUcxpu/SW5loilPKHJWTwNJR6TVoJjpqSzGakZbMpeiJXAoRwbGpQdLF6YQCSbUXRL1kXH3z0hlMFqvNnr5sVssJQpIkLFcMEUBdLrxnf/Ob33BeVj+9J4Jux+qoeVWwSAj6aBTWJZuj6acNyR4QgdSBMW5/rK+MwWo1tSiJ1E+rwWI1txwJZTmIxjrtxjOt7ZGUixIFoAmZitFObxAXphx6QpHsK3OrQxXS2hPyBfjF7r0SoQ5O0okMaSmeZDBmi7klpYrJtJ0M+YMI1NRLb7aalO5wMJwZXjzoD/X0PkaWpVd6isiy0uK4/iWAmfrDJAFrwkxxRh4m863jNOtPS4pPPtxht3hCxZ9VPZctIUHpOa/t8OHDRTqLB7z+xAyv39OnFj1RisMine1Rk8NpKVJNsgaBADHaQmudNkeHL4ACKxTwdTjag8p4u91MIyZXu3N8/GGnzd3pD6Qe2T3P6GZ43KButlqgBl63LxSJhAKdbqsjZHFMgY0J+sMpTibNesSCnb5AIESM6rxbg73dM0X5vtvm8PpT3fq9Tpv9VnxXdPpBjD1T9CSDMTjc9tHdj7ntbl8AMV6n2+aKGMb31Xa4prW+jJdsB4FEUSM67R1xU1o1n6YuerPZyEmf0Sy6l6qahMvvaTWZjJl2hncCdoSI4Dt37vzJT34yvJGo/uw1areG7XxLrW2C86BYv3795z//+b///e95+W9gjFloi/kGZsKLUn4O01btayx7zPzpaeT++KEtbfOmjR/dijKawAgTpy1ate1EFLTUCF/dtir1FMM79GszlnVlQH91R9vsiaNTlUaPn7FsI0bEhzbOG9/a0jp2dsoD5fjuVSmfkdbR4+d10VzeLQ0f29e1bPaUsWq3Y6fMXrYx03TaJjjL7Sk1joGvkwyGztYtmsbgmOHYKfPW7T7UNTvbZPnYjvvmpYfS0jqeKHD79qXCdfWaARf1L3lj9zI8VGakptZIV8VtgvMm/+ijj+KPTMCuvHy5rSACI2ir+gSrsIdYyBdkX9jvFfV7Og2+pN+eLvGlL32JEPHXXnttv+Wr8IDDstra2qZMmTJ//vyc5pMBh9GV9EYCDsOJfJyw3a72x2L6GR1+v9uiR0IXimDMijTGmtLTyyUIVB6BZNhtvshn7IoGnb0LMRl0mq4IWrZEG8z249vf/vbBgwdvv/32yqOUbpETVFeuXIl1Hl80Jl5V6mW4N1tBujSYplKuaCe56s2XMB3c4D/+8Y8XOsO/uI4YwhMX3bdxy8auVUunjWcurfgn73iVjebGZTPG93kBpJwZhU0ZzMqQsqUjkAoOgFt+ZoWl3OxbJqZ9NktvRAslq82XMEf0SHgv4sOohfk25RjqRaKtLuf41iltu48dL3oRJCMtGT4Juan2Y5ihj370o9iB/PWvf83uy+TyBzvMUa/z6vmujlDS7O7aHY36HUmv1WyZ3xk1qmHG3jh+aJsj2eFwDufwSNmwSbrCCBiIZY2Pk9ubdvqN+dztYaO7M8tRs8L9NXJz6nlZHMtdXAnayFPTyNjrRUv0Vq/Plex0tYcVtGMFV9oxQBMQXXnllaeddlpBqDi92eULx4i2kkxEw/4OpznutZmvwErYtSUSDRJ2MCXa4jAtb6dLj6o+pom5yCAqiUDIaSCsdL8XQSBr8NaNLp/PEW93uJ941ut0h81ef3uBRUglJ93QbRERfNKkSWwNxf2mGu+xfv4lOku735vsCAbj1mJeibqMVX01pl16m/xW3HTTTUhysQPBXL14xZjfYft/YcPSLQGMU3OLGCAqgZSxTV5+bim5azwELB2hFz0DDFtnMA7wtGKPDHZfTFU8XpVwV6zVZm0I+0wMajDRJNGsc6zXvOpHS1LOik6vr5+JW7118y4pGBHnZWGljon6eeedR7rgeTLY7iYmfSDUacvXsyfDHZ1hDswyFVSSjEZHAMeowggmjT6pZh8/h5oQWwXXxcmTJ3PYSbNPt6bzq5eMq6aTLL8zOJIJEyZwXhbGXQWtEYgyYfF0FBCSRLjDZl8bs7S3S0CVAtAkQxCoDwKQEJvNRpykY8eO1WcETdqr0JJSXyxMMedlFUYRhr8iYEV+zApOMXJYrLdGDEsxEhaupFSQpZwgUAMEiLnHeVmQkxr0NXy6EFpS6rt++9vfDne8ffv2/CjCisXpNIU6iBWcbioZI06txXSRejg8cq9e2/9SO5JygoAgUFUE1Ijgv/rVr/qPk1TV/puzcaElg3ivmdOk807DMLv9naaQw4gA3WTQn3PJDf6EpW1LNOJ3mfMVKIPoTYoKAoJAtRBQI4KjhD9yJBMCrVp9DZN2hZYM7kVz9ifcMVGEc6phRRCIRAIdLqfT492y41A8Guiwq1Hoc8rJjSAgCGgFASKCq+dl4RWvlTE18jiElgzu7RH+iVBxxbhjvcnmdHs8bpf9xFkmg2tYSgsCgkCtEVDPy8KBsdYdN2N/QksG/VbhjufOnQt3fPTo0UFXlgqCgCCgGQQ4Lwubmu9973tEA9PMoBp1IEJLhvLmcIY/++yzMREu5I6TsaDHZleDWgylaakjCAgCNUTAYrFceumlOMO/9tprNey2CbsSWjKUl6o6w3OadCF3nIz4OSmDszKG0q7UGR4IPPPMM9u2bfvDH/4wPKar9Vl+7GMfY4jf+MY3tD5QbY+vnn7vAyOzd+9evje1zMsvv0yYz5deekm9JXbv2LF1jv2oOsOznSHCDyEgM3PR2zvDUQ6902VyJCEI5CEAFdm8efMjjzxCJAWCRH3gAx/A4jyvjNzWDAEcxFCCtre3DxQnqWajadiOtEtLoBYvvvgiwZlVbInUi6sgDAEizroTEnVIOMND8CAnHK+S9VugyzohtmHXhQy8ygi87W1v+9vf/oaYntOgX3/9ddYSwhb2JVXuVpovjgDbwauvvpo4Seeeey4RhYsXktwBEdCujOvd7373P/3TPzH47Eisb37zmzmcasAZ1fShGiGuIIpwTccgnTUuAqxtCAnjf+655+69917CvsGswIU37owad+Rz5sw588wz2Rqqb6RxJ1KvkWuXLwERVNwPPvhg5tXCo/zjH/+YNm1avcAq7Bd2RLjjQlgqm7N27Vp+aivbZn1bYyVzxl/2GFjYZBILnaPdEe2eccYZmKu+733vyy4j6aoiwHmLfMsejwezrquuuqqqfTVl45qmJbD8DzzwQDbucCoaEXBlRgV3/JGPfATumC9frxc/9wwwFUtwHNmHP/zhijWngYbQvf/sZz/LDEQV5L7lLW/BLJAldMkll7Bhgi/PFJBEbRBAusXZi+vXrz///POzlaC16b3Re9E0LWHXbzabiX+lsiZE0Zk+fboGEcfdBNUOzvBsapBaaHCEDT2ks846q6HHXzh4fF0zmYhtYUre+ta3IrydOXOm1rZKmXEOkwRU/Pnnn0fSRVz6VNBWuUpGQLv6EnUKmH5DSNi4cfHJaVM5CZHjvCyOhX/yySdLRl4KDmsEEGdBRYCAswxuvvlmn893ww03CCHRwpr4xCc+8b//+784I2thMA00Bk3zJeAI8WDLpp4aAo+iWcYfE2Gs1B9++GEGiWN8A60AGWpdEEBaO2vWLJZ3lgVgXQYineYjoJ6XtXr1ajkvKx+aAe+1zpcweHh/RMns/TVlwVWIauY06WLnZRUWl5zhi8A111zz5S9/GXGKEBJtLgIigqMElfOyBvV2GoCWIERGJ4lAQJsCrmy4lyxZ8pe//KXYeVnZpSQtCAgCWkcAJaiclzWol/RmvD0HVaH2hbFs+dGPfvSv//qv+HPVvvdB9Yg4jjhduAhgBCIeT4OCTgoPNwRwo/nP//zPH6cvTFeIBYDSW72FXVN9y+qICSbC48eP/853voPI65//+Z/rOJJG6boBaAlQHj9+/P3vf3/dl1cpLxUSwklZKOEvvvhisQMpBTEpMzwRYI+IxQGxkaAihAD4+9//ToKL8BYOh0ML0r/W1lYICUp4NrKkh+drKn3WI7CPKr10zUoSMQUDfEwnCVLCOmOQqq0tPlwoxLD+1rK8C33JnXfeyady66231gwx6UgQaDgEvvnNb/7gBz/APjMzcr7097znPffcc08mp+6JVatWsTskThIq27oPRssD0BwtgYqorr+sKjRgCIve9a53ZRD87W9/++tf/xpeGKKCAvNDH/pQ5pGmEocPH7799tsXLVqEQl5TA5PBCALaQQAxF/utzE6RgSFZ+uQnP6mp2BbHjh37/Oc/j3PC/PnztQOdBkeiLVrC2lqzZg1ri+MzL7roov7wglPZkb6MRiO2+VpghwuH+sQTT2zZsgXLQsyFC59KjiAgCIAAjll/+tOfsj18CZuktS86HA6j2mlra2N3K2+tPwQ0pC8hsAS/vLhufepTnxpY2YWJMAc1E6l79+7d/F5PnDgRgVJ/M6xXPiNEo0gU6w9+8IPstuo1DOlXENAyAlCRX/7yl2wfGST/XnjhhYSQ0dqAibygKkFhmLCv0drwNDIerfzGwZFg/kTkJc4mIRx3Kegg+4JB5gQIWBkkY6VUqWUZPhI8mYuel1XLYUhfgoCWEUDxqepLVEkXoiRtjhZPZKiInJc1wNvRBC2BEnzxi1+EI8lbSUd2rrvxyikmIkEbTVOuvLlrT3fhTK677rqWlhbidRc+qnsO3BJRxOU06bq/CBmAZhEgkgWhIlS+hB9rzdrUqOdl7dmzB/GJZsGs78A0QUsw4iYENxxJNhbJnbddNXfl3tb5d2/YtOmhOy/u2XzL3Ou7DmcXSaVhYpYuXYo0SZvvGJ+YqVOnEipOg5xTPpRyLwjUAwHiWWAipbWjiQqRwA4IB0bsmI8cOVL4VHLqT0v4kcVwC+lW7svo3tzZdXCMa/0G95zpU6dOX3Dv+rZJPbs2by8gJoqCsAvfeBrJbUErd4SKYyhyXpZW3oeMQ2MIwItASAjhylessaHlD4fAKjgjy3lZ+bik7+tPS/AggSlBf547vtY5a54Lb3JPyOSOGo05VHd3MpORneB8UzQuODplZ2okjQiOM3Y4zQk9vEaGJMMQBLSDAFZbsCbaOXt7AGTU87JQgiK4HqDY8HykCVpS1NJON3rMe8f0+Zp279q+Xxk1aVLxELywJlyQJW2+Rbhj9bwsrEG0OUIZlSBQRwRwQNag+VZRQAhsgRJ006ZNBw8eLFpg2GbW35MTZ5FzzjnnJC/g8Oabb97cM/P+tqn9nk4DLdGyTkLOyzrJK5bHwwwBdn6oOQ8dOhSNRpk66vfNmzdzggsXR5Ri8a81L5PM+0EJyuDlvKwMIGqi/v4l6Mxhb/HGyBtZ5jZ5oMt59S3Pjbtz00Mf/+f+aR/+RBgXnnbaaWjjNWgDDndMSLHHHnuMBDHjMrOThCAw3BDgk8fwcvv27XwL5557LmoSZNTqRfyr3//+98RyRf1JhC7oiga/Zd4X3zKDRAlPqK7h9vr6m2//v8391ah0frbLa2HbR3bedt3Cru7pa564f8F7++VJTtSDihDJh0CQ3LMKMTdU/yXB+VRD2ubE/C63L5pIJPnPYO/o7LAZCwdZYo6cl1UiUFKsWRFAcvDAAw/gnIhEi6vQk4w9JY4ByCqIk7Rt2za2/y6Xi69Ya4BA81CCEmQdogIV1Nrw6jKe+vMlLBesOOBqC+ffvfO2qxc+espi/5P3znrPyageQVXY48yePZuw1fDLaCbY4BC8a9++fTwicC+Wxz//+c+JrlO0r8LeUznxyN6E/oKpl01KhjZsfUF/mdthHlm8ZGm5+PO/8sor7GiIJCah4krDTEo1CQJYx+BGxuHEGPFju0X0iv4mxiPMpVDIv/TSS4FAAH9kDR6oilCdo3yRyxHYAuuh/uYyfPLrr3tnVf3iF78ogvjhrusXdikLNmxaPrVPBV+kXCqLkD6EfUSDB51gpaq8Dv/CJnNlKiGcHQQhoZrB6nS5nDZ9OPi8blqH12nINDXkhJyXNWTopGLjIgBHwjGFSLOXLVtGSJJSJqK6juHCjEAMOlRKlRqXQQl6+umnM68a96vN7jRBS6AEBw4cyAWoe/OK1T/STV88U9m/s+/ac6CI6zsVUZYQOVjlhYmZgzN8oehMVVQMjpakxpQMd7h98Yker9OYui33QtQG246wuDgFLbd5qS8IaBEB6AGnoxJqL1uulTy8dcX1l080piJbTPzQNbdtPpAsGDsuzJATGBoNWtYgWkDSxW8X4riCgQ+7jPrTEn5bYRIRQOVif2Dv3qPK0aduuSr3Wrm9kJhAikKhULa3I2GGaRPRWaZNpF44Q9FWJqfURLTT7Y0aXV63OVtdk4wFO91Ou8Pp9gaig7XzxQbaZrOxndHg51EqLFJOECgZAdVkC4FBNiFRjmy98crrug6e7boXC9v7XROOdi256sathd+3AjlBiFTwE1Fy99UsiCKWUF2PPvoox0xUs58GaLv+tASQWCvQg61bt2YBNvnu5/+n8Hp1w5xCeRdBIeFIYEeyqivEVfy3f/s3uBM11A90BaLFz/cgdxAxn7v9OYPD227NoiTxoNtivsIdiOl0StTnNJtt3kjhhip7NAXpBQsWcJr0+vXrC55IhiDQbAg8/vjjGGuhYMie2OHNa586enHbhodumEOYoVk33H+/a9zRpzYW2SxSi90hll3a3HtxRhHSDkyEYbyyJzjc0pqgJfzK89P/1FNPEUN+sC+Ao9nQlOTF8lIb+Y//+A/OaFNtCmFKOBkN2Re05DOf+cyzzz6r0piBu4v7PZ7v62a3d9j6QtonIx12x9q4ZV04GvL7fMFI1G+JepzeyMBN5T1VuWP2az/84Q/VR6pAOa+Y3AoCjY4A0SjYsxcaO41Z8Mhzz6xf3Od8PGrMqBYF1XyxCXOaEawJ30uxh/XPQ2r9l7/8Be6k/kOp3wjqb8elzp2z3FF4dHV1sZZKVGlgOMheAO9TDsTtz2oQryKCl7z22muIvKxWKwzphz/8YX7H8fNACcNGCUltHvjxkO/xuNF8lk5JBG+65tYXzPcEvNYMKUmG7/iIM6C7KRC8w3LComuk6Yzoem/YuNA5KVMsr82it5wgzefh9/sZJE5bK1eu/O///m/su6CsRctLpiDQiAhgV4mA4fLLL88fvG5k67tG9plnHnlizZeePuXa2//DksO+ZGpxMjy7Rj6WTI52EnzIGJ4R9pEIFzjGa2dgtRyJVmgJc+aQRA5y//a3vw3TgFx1AGMPqMjTTz/NmyPUFYQEOtQfZDAl8M+wO/A96m80GnhMDGFLu7u7N2zYgBk75AQy1ttCYqfXteSmjsCvR/5fqP2enWfd8fj6jxh6HyrRe65xPq5z+R93mfo+gmRkw12Pv3bZZ52TBmsvzMpDA09sH6yWsTdjtJiFkJnpTxKCQKMjwCeGIX4hX5IzLxySl7jW/2POA/cuGJMlTc4uAyGBxckTZWcXqG8aEjLMz8vSEC1hKWBFzq88odNwB4GfYDvDLyzMI49I42UKF8LPLlwF1r2IUJFWnXQXzw80m/28gxcxYL/gggvgVPBBefjhh2EIoCgYLCqK7jybyzn1lLDvjtVbfzfysvavfbaP20gGP+tY/Vvb+sc/e0HWek98r/0mf9Le7rmsj+aUuKyxdETmBtuECA7VDn77kLqLL764xOpSTBDQPgK/+tWv+HIHoiXde7zOa1cenLRm49oB/Mj49iEnbDHZaKqCa63NHYEK8VvxaRtoslobdOXGo63z3jPzQnkAa8wq/NnPfpbJJAEviT8K74x/T0pFsisOkFaPPoR0oau/9tpre6Ve8ZDX7W4PxE2Odq/XZUF8lQw4DI6IMxT1WrKai3RYLO1KeyTsMWXllpBEIYmjk6q2US2YSXPkDoK+EmpLEUGgMRBgne/fv9/tdhcf7uGtNy68casy5/5N984aUDiEbQ7kpKenR7WYQqxdicAWxQc15FzGdvvtty9atIg98ZAbadCKGqUleWjC27IZqRTxyGtcvf3Nb36DGp89BcwK5sVpHgW/93Cnx9WpdIR8aN8jHrPFbw3FsklJzGczL47at0VSBQZxwZF85StfgffPNgEgDVG54447StQYDaI/KSoI1AkBaAnHEXo8niL9YxZ81ZLtZ9/5yEM3TC400MytQDt//vOfr7nmmhUrVqBVVT8c7DO5Mv7IRImFcUGgnVu1pndPPPHEli1bOjo6hpviRBN2XCd91WxAqkpIGADRTYiu89nPfpa9D3uojRs3pgwQDRaXL5JNJ/SYAfdd0U6XGzuvjmw7r76nA6XYVa1evRpdDoUy5ARCwocBNzZQTXkmCDQUAkSjIG4QRv/5o07u9163ZOuoOzdtODkhoS6aRaQRfDjLly9XZVx8LwiHM4SE7wjRd92jrXC6BFHFhuF5WdrSl+SvtprfGwwGmFOW4/e//331uBt2Ovy+pwdiGBndcM/jv73AYTehZE/G/Es+4vreyIW+x+8YtNI91R7fA58Z3wYRw7hVKQrfBlbqhL1L9yj/CAINjwCqSgIDs7zzYoEffmSJ03fK7Lbrxv0VydCJi9NvR76nNXu/ps4f33IUpZj+s6ekQZpSzfpV4bBahjTGOMRoqa82hWGgi4U1gcgNKwFDY8i4av898YOOb9R3v/tdtPSIvBB8pShKMuK12z1hncViTEZDz8WNi3zBToexcOkPasAwQOxikCmrvk6sxQcffLDafNigRiiFBYFyEMDABK91ZFPZfu9brz/zui09+c2Omr8pev/0/Fxl1apV7OqyhVfQJ0IOQ6JUckKCLxTL46KuZgXtVT0DJTwfNaKO4WOWKbRkoFXFrzwWZXwJeKKglidw6YgRPdGgPxCKJAxmu8NhMZRJR/p6pxfs09jL8FXcfPPNsPN9zyQlCDQ4AuhL0EESj2sI8yCuNo7MX/3qV/M2WHwyuAdi/UibfDUwJQTunTFjxtVXX805RkPoqLJV1q1bR5xjFCcY1FS2ZW22JjKugd4LzLJqOoytF6o/Qtafc864cZMvmXqZ7TKL+SzV0SoRCUV1xrKJCvsXrIHhTlAw4sY4ceLEgUYmzwSBhkKA5Y3VIsbBg13YOIexx7r++usLN/jk0CCGwkiGcUCmDLoKZF+Uh8WHjxkgrH0NwCMkJVEt0BUhyla7w7oH57b6iuCqN3GhJSfHFkNkVgMWw7ihfOtb32LtouQgmla6ZiLosn7YHdBfs8SS8Xc8eZPFS7Dtwi2fHRbfD94zxQtJriDQgAig5DCbzXgiY1pCbNMSf+XZwGEWRVDI/lwU+TB/9/9fNdIAABH5SURBVLvf8UnC9Hz605/G6RhxNJ8n+k4OPqEXPKDx2aoLYJA3TlSCfuBmALUjhhOaURyrGVJdxlPtTkXGNTiEWQ1EPWH59poOnxoLettDZu/gTbnyOsZKmHBDfGl49aunNSBcJugL2yvCAYjIKw8uuW1EBDDuX7NmDaJj9VzeAaaAsh0VC9Zft9xyy8AabFojIj1qkuxibMiIHU78YX7QOWUEg0lVrTJAj1V6BDlUrXhglaAoBHPK1vpUqdO6NCu0ZNCws0x37drFDosoLISOJ459nhh3sC1CP/hsCMmFaTxsO2FU1PgxHDbMhgu6RRQK6AqcCt2V2ddgxyblBYHKIsBPP3oOLpY0qx0ehQRrHu6fpc5GCh8vFjxUhJ9d1XDrpAOgzaLfBeoTgi1hQUP78+bNq/3Z7AwMNzJmBBVhFvx0wJ+hRznpjBqxgNCSIb41dhl8DzDg1L/yyiv5lR+CGJSlRsB8PPzR6s+aNSsvKHdmZHxgGERycWK8No+/zgxVEoJAKQiw8tXAFmyk2DNlV1G5cBjxSnmK0BeqGogKEieIE55k2d1VL42Y4b/+67+wpuG3ImNsRgKbNKRw1eu3Xi0LLSkLeZapaujFtqjPdLi0Jql71113EYwL4xaVERm4HhQFwsMeB3IiIq+BsZKnjYWAKtSt6i8s4jXETUQHzw2VVEWcMF3DayavA2Ru8+fPb0ptqOje89714G4zhl7Iu/BOwqgcEywOTTmpcFYlJJgz4mnfHzuSNxQUiZAQrLzg2TGGgVnOKyC3gkCDIsBirvZ6ZrenWtDgP8+ejFixaCIRrFUPMbyeEWohu8bxBRmX+pvQxPFbhS+p2FrCbhglCjEiWaMOhwOLwAGaRmZKvAd8dBEW5xQ7sn3FkhvX7hq17JkfL++nASxDMB1eu3ZtURlxTmtyIwgIAgUI4PbBR4QysiL6zoLmczJgufCMOXr0aEbSxeOmPDVL+JKcF1/ODVbCxJq+8MILMUFBPst6hUE5ESMyt11kxBydsnjxYkK2ZD1JHt5659z5X3rhlHf99egpkxYvtvYTNhWmBFYdTmiwpvpZfUlSEBi+CGA6fOmll/J5okRRVZ7s/3pDJVUYFvgtrMgIb4xHAU3DqcCgoBOqlDaowsMtozmhJWWAV6wqxAP7E+IF/fSnP8XCPdcZ5UQF9kQY+7KacxvYt3rJ+rffssk365UHnzh64XX90hJq8Rng6SKHMOYCKHeCQKkI8IPOR4QYCg95yAkBk/BOR2FTDWcUJOFs+6Af/CYwPrpGttZ8G0GhJaUuvkGVI9w0yxS2AwaClZotnEVTQhwhrLZymRKaH3nBzMXXXjRad+gp7+aT0BJULAjTkHEVOgMPapxSWBAYzghAOeBIcBBGAIVdPj7zsBHQGFW3UVlkYET4TUDkhTAc07UihxZXtr+atya0pFqQsxzV4+VHjhy5fft2/JU4dAF7RHRxkUikWAQ63Ug1KEsJtIRBY4CPMK0/f+BqzUraFQSaDgGkWzANBOdGbsxhE5y/h/F9NU4fgUEhThLcD0QLujIELwItY993armWR9m4Y8MEEP0ev/gEp+NgOKLUsQ8qxQL4pFOGTUb2etJiUkAQEARKQQBh13XXXcfXiukwARnf//73Y0FTQWcUjJLZR+J0ghsAX+4nP/lJ1DZc0C3sMyFmjW5KU59INaW82mYqw+8+3iderxdVCuspc3pPOXOEIBVar5fToNQVBKqFQDIW4JjrETprZyyni/7ylWTU77abjRw9pzea7Z5ALJlTr3o3SKKIcQItoQtOOMVaEpFUmd1BRTo7OzHaJKYLPBD0CbEEt9At0olEAqtObhGyIQAvs686Vhe+pHbgs/FhDcGpIJsqv1e0+sjQym9HWhAEqopAMupzOdxBxZjnD9VfPoOJB5w2Z8jo6gh0mqAqHR6HNRGIdA7uGOxyJnX22WffdtttWN4TfO9zn/tcb/C9dw6hTfWcFYxxoBZ5p4Flt0Y413RkmW2cN5EdWCy7jMbTQktq/YLQ7CHpqkiv1dAQVmRg0oggkEEg1NEetfrCnoTL6MrmLvrLV5Sorz2QsPsCXkeK/FgsZiVmcnX4PDa3MdNqLRK4iHHkhBp8Dw3HEJxRYDiouHDhwosuumjgEVOAC/EasTAGiIs8cCP1fSq0pNb4s+kgGgpcRZlaE9x3iQZR69FLf4LAIBGwdITD+FEl/Hn1+stXYqFgVLF6+rgQg91ucbmCobjbme2PlddeVW7ZruEdgt8Y5jM4jbELLD34HoQE7citt95a+pd+zTXXsNfEzpPJNJxZjehLqrIEB2gUgSyyqXA4nF8meXj/HkyId+48cETp6T66P5Xcs+dAd3651D1GXFCjzBk7xYpIniCgCQT0OQ65fUPqL1+JRaIKZ3xkicT0RqOB7Fhf5dqmkEtzXCP6TuJo4TTmdrshLep5jv0NBIEVhISS+YQEj+SbLzeefuaVXfmhutSm4E7gYyAneDT317g284WW1OG9sCLxDoEe5PS9v3PJDALYX3XV7T/6s/LKxptSyRlzV+/MKXTihoBCGH5UNRZesW4lTxCoPgIooxWdIYuUKIper1NS2XW9sKCZM2cOFOUDH/hAV1cXehS+4qK2lKjQUaRjZJxHSJIHHr3x8g/dsjfZOuBEICcEDucbH7CU5h4KLanDK4F7hQyw2nL6nnz3c/g05l2xh2blFErdoKY7ePAg0YILnkiGICAIVBcBLGg4DJhTSWCdsPLC1gsVfV6XhNOH8OCPnJe/a+3qg1Pvf3qTa1xL3pP8W+ri1Qhnk/9Aw/dCS+rzcjDowpprCFsPCAmxvNDONV88n/q8CelVawjo9QYlGc9hQhKJJLxJDqtS31Fz7O5nPvMZ9OQ4hXAeyd1338257pkhYbuF6VfmNpOYdOfTT989a4xOl8npL0FgC04J27NnT38FNJgvtKQ+LwW+5M477+T8uK9//euo4kscBKo/CAmMdsPp5UqcoBQTBBST2ajEYrEsYhKPxeKK0WzSGjh4h2A6jHYd+RunlaBsx5WEC8evoua/raP7CddabGLQEjzwiz3RaJ7Qkrq9GJWcHDt2DMeoIqr43HHBxCCoxXkejgRjj9yHcicINBECBqvdrIT8wQwxiQf8YcVi7zPs0tZkMR1evXo1Ho64IeMdwm6P8eVpSoYwYliT0neZQ2i/4lXEJrjikA6iQcjJF77wBUw+sCuHThA69LzzzmMNqQsR5TzaE3hnVHxYbaHxg5WhyiA6kKKCQJ0RSETD0XgyqSQj0IZkNBIKxRSdDiYjGSmabzHqTM52h9futnuUdrsRbxOPJ2RwBXvtgcMdVnfQ5g15LHWeWVb32abDHGJUVCGfVbykpHqyEVxOo0izhZaU9F6rVwh5K3wGll3q8deIvPL6woAYhymMRhplSeWNX26HNwLhDtsVD2cM29defcla8Bi7bHdnonh+zGtR9LbOkL/d3e62exOKwWzzBLwea6+SIRGNPBcxZpgWDaGrmg4TXwvNfPnDUpmSBvrqhZaU/9Ir0AIUBXLCRVsYFKrHX7OMGmglVQAFaaIJEbD5Em/4is6rv/xUYZ3R3hGwdxSrl2qwWL5W8k4//XSGAiXIPzJVKwOs1jiEllQL2SG3C11p0IA8Q56yVBQEmgYBpNAYBGNWg5tIOZMisAVi7XJaqHFdoSU1Bly6EwQEgSZHgBjy6DgLaEn3gT0Hjvb0KD37/4zq6CCRLQ4rLS1jJkwe0yu/y8YFWtJYVjZCS7Jfn6QFAUFAECgXgZkzZ2IojO1lrmXw3rVz526EjKhX53VXdZI62/X95++e3JvZ+5ezjpCSQZN6Mxrg74iKmBw0wERliIKAICAI1AqBb37zm3ga4nQyBK0JRpt41HMwV2O5kYl/Sa0Wl/QjCAgCwwYBzr5D8QlJGKyPCJ4A1EJT0liEhBcrfMmwWd0yUUFAEKghAhhkfvGLX3z99dfhMEp0XUQs9uCDD6puZzUcaWW6ElpSGRylFUFAEBAE8hCAnHA6L/7whOcibPAA8i7YkVAoRJAkTtwiWF9eOw1xK7SkIV6TDFIQEAQaFQFCPRIUHGEXIba4MoEtmA+qES7CfhNF6YwzzoCKNJa+PfuVCC3JRkPSgoAgIAhUBQEoCjHkOeHq+PHj2R1AQjiLCJeyhlOQZM+CtNCSPEDkVhAQBASBKiKQCWxBH6hGUNFXsbMaNi20pIZgS1eCgCAgCDQpAmIT3KQvVqYlCAgCgkANERBaUkOwpStBQBAQBJoUAaElTfpiZVqCgCAgCNQQAaElNQRbuhIEBAFBoEkREFrSpC9WpiUICAKCQA0REFpSQ7ClK0FAEBAEmhQBoSVN+mJlWoKAICAI1BABoSU1BFu6EgQEAUGgSREQWtKkL1amJQgIAoJADREQWlJDsKUrQUAQEASaFAGhJU36YmVagoAgIAjUEAGhJTUEW7oSBASBJkYgHvRYDSNGmD2RvEkmo3633WzU63R6o9nuCcSSfQUSEZ/LajKkn1kcHaF43yMlHvI6eabT6Qwmq7MznMh6prmk0BLNvRIZkCAgCDQaAslYwG0xOwIJfUvB0OMBp83pT1jbA6GQv92a8Dms7uAJshDzOWyuoM7pTT3zmKIdNpsnfILSRDrsdk/Y4OoMhoKdLkPYbbN3Rgta107GG3IJAoKAICAIlIXA7mUTJy7qevHYtkWtLRPb9mW39eKqiS2t8zYe6817tWt2a8u0+w6l7ncsG9sydumO473PDt03paV1drrssS3zcpo6vrttfMvoRdsyZXvraOWv8CXaIesyEkFAEGhQBEyeYNjnNOkLhx8LBaOK1W7LPDLY7RYlHEwJsyLBYFxvc1h1vdWMNoc5GQqE4EwiwVAyddv7SGex2wyJUDDSm6G1v0JLtPZGZDyCgCDQcAjoDYYMQcgdfCwSVYxGY4aUKIreaDQosUhMScZiMcVoMmZVoGQqO67Eo9GEYjLnPKNkOjurvIaSQks09DJkKIKAINBsCCQSCUVnyCIlEBO9Tkllp/5P3/TNWafX65VE/MQzdPV9jyjJXTJVR5OX0BJNvhYZlCAgCAxPBLJMvBoLAKEljfW+ZLSCgCDQUAjo9QYlCaORdSUSyTSTkWY0Ujd9VzKRTCh62JgTz7LrpdkYGJe+0ppKCS3R1OuQwQgCgkBzIZDSeaAXySIK8ZQ+xGg2KTqj0YTiJJpFTGLRqKIzmQyKwYQiPxaNZYERRcViTGVr8xJaos33IqMSBASBpkDAYLWblZC/16FEUeIBf1jBKAuaYLZbjYlQoNehRFGiAX9UZ7Nb0OOnSsSC/kgvCCnzrni6sd4cjf19c3t7u8aGJMMRBAQBQaChEEjGInsj0V/HYi8E/Vt/e5bFrE/E4vHkyLPO0ClnmM76te+urwVfO8s48rXYD+9a8tnAKUvWd15jPEVRzjKP3Pu1uzrDpxiNIxMvBO5wtYfP8qy/5zKDopxynumUH95zly9yxnlnnfLHvX63q+PXk+7x3TEpxZckg+6pCzv/b6pj0hnawUkrji4yDkFAEBAEGhSB3cvGF/6mt87bcmI6xw9taZs9cXRrS0vr2CnzVm17NWuax/d1LZ0xfnQLz8ZPW3Tf7oxPI2WO7b5v0bTxVGsZPX7a0q59mWfHuma0KOPbdme1U/fkCEZQCILkCAKCgCAgCAgCpSMg+pLSsZKSgoAgIAgIAsUREFpSHBfJFQQEAUFAECgdAaElpWMlJQUBQUAQEASKIyC0pDgukisICAKCgCBQOgJCS0rHSkoKAoKAICAIFEdAaElxXCRXEBAEBAFBoHQEhJaUjpWUFAQEAUFAECiOgNCS4rhIriAgCAgCgkDpCAgtKR0rKSkICAKCgCBQHAGhJcVxkVxBQBAQBASB0hEQWlI6VlJSEBAEBAFBoDgCQkuK4yK5goAgIAgIAqUjILSkdKykpCAgCAgCgkBxBISWFMdFcgUBQUAQEARKR0BoSelYSUlBQBAQBASB4ggILSmOi+QKAoKAICAIlI6A0JLSsZKSgoAgIAgIAsUREFpSHBfJFQQEAUFAECgdAaElpWMlJQUBQUAQEASKIyC0pDgukisICAKCgCBQOgJCS0rHSkoKAoKAICAIFEdAaElxXCRXEBAEBAFBoHQE/j/CHhcQtGQ/GwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "-f_sjOTQAqA0",
    "outputId": "f2282246-bafa-4453-a3dd-ba9379975d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1., 1000.,  110.,    0.])\n"
     ]
    }
   ],
   "source": [
    "# scatter_add() exmaple usage 1 \n",
    "\n",
    "# Say you have a graph with 4 nodes, and there are an edge list that describes their connectivities  \n",
    "\n",
    "Edge = torch.LongTensor([[0, 0, 1, 3], # index for i \n",
    "                         [1, 2, 2, 0]]) # index for j \n",
    "\n",
    "# It means that the 0th node is connected to 1st node and the 2nd node; the 1st node is\n",
    "#    connected to the 2nd node. \n",
    "# For now, let us assume the connections are directed, i.e. 0th node is connected the 1st\n",
    "#    node, but the 1st node is not connected to the 0th node. \n",
    "# We want pass connection messages from the nodes in the first row to the nodes in the\n",
    "#    second row in Edge.\n",
    "\n",
    "# And for each edge, we have an message we want to broadcast from i to j \n",
    "message_i2j = torch.Tensor([1000., 100., 10., 1.])\n",
    "\n",
    "# We can use scatter_add() function to aggregate these pairwise messages onto each node. \n",
    "\n",
    "node_message = scatter_add(src=message_i2j, # message array for all the directed edge \n",
    "            index=Edge[1], # index to all the jth node to which you want to pass your message \n",
    "            dim=0,         # feature dimension you want to sum over \n",
    "            dim_size=4     # there are 4 nodes \n",
    "            ) \n",
    "\n",
    "print(node_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "WQuj4iV_GVCt",
    "outputId": "fcc1c6aa-54e1-41c1-8491-d2f6b9cf807c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1010e+03, 1.0100e+03, 1.1000e+02, 1.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "# Now you can look at your results, you can see the messages are assigned from message_i2j to all the jth nodes you specified\n",
    "\n",
    "# If you want your graph to be undirected, i.e. the ith node is connected to the jth node and vice versa, you can perfrom the summation in both direction like this: \n",
    "node_message = scatter_add(src=message_i2j, index=Edge[1], dim=0, dim_size=4) +  scatter_add(src=message_i2j, index=Edge[0], dim=0, dim_size=4)\n",
    "\n",
    "print(node_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mdkbEciNdVsL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1],\n",
      "        [2, 3]]), tensor([[4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]]))\n",
      "torch.Size([2, 2])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.split() example usage \n",
    "tensor = torch.LongTensor(range(10)).view(5, 2)\n",
    "splits_idx = [2, 3] # list of integers \n",
    "print(torch.split(tensor, splits_idx)) \n",
    "\n",
    "# you have two tensors with size (2,2) and (3,2) respectively \n",
    "for split in torch.split(tensor, splits_idx):\n",
    "    print(split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FNZxI5T9dVsM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4],\n",
      "        [18, 21]])\n"
     ]
    }
   ],
   "source": [
    "# And you can sum the split array separately and stack them together \n",
    "print(torch.stack([split.sum(0) for split in torch.split(tensor, splits_idx)], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8xjflAkwu27Y"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import ModuleDict\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A GNN model.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_convs=3, n_embed=64):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.atom_embed = nn.Embedding(100, n_embed)\n",
    "        # Declare MLPs in a ModuleList\n",
    "        self.convolutions = nn.ModuleList([ \n",
    "                ModuleDict({\n",
    "                    \"update_mlp\": nn.Sequential(nn.Linear(n_embed, n_embed), \n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(n_embed, n_embed)),\n",
    "                    \"message_mlp\": nn.Sequential(nn.Linear(n_embed, n_embed), \n",
    "                                                 nn.ReLU(), \n",
    "                                                 nn.Linear(n_embed, n_embed)) \n",
    "                })\n",
    "                for _ in range(n_convs)\n",
    "            ])\n",
    "        # Declare readout layers\n",
    "        self.readout = nn.Sequential(\n",
    "            nn.Linear(n_embed, n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embed, 1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, AtomicNum, Edge, Natom):\n",
    "        ################ Code #################\n",
    "        \n",
    "        # Parameterize embedding \n",
    "        h = self.atom_embed(AtomicNum) # shape=(Natom, n_embed)\n",
    "        \n",
    "        for conv in self.convolutions:\n",
    "            prod = h[Edge[0]] * h[Edge[1]]  # shape=(Nedge, n_embed)\n",
    "            msgs = conv[\"message_mlp\"](prod) # shape=(Nedge, n_embed)\n",
    "            # send the messages to nodes, undirected graph\n",
    "            # sum(Natom) is needed because we collated the graph\n",
    "            agg_msg = scatter_add(src=msgs, index=Edge[1], dim=0, dim_size=sum(Natom)) + \\\n",
    "                      scatter_add(src=msgs, index=Edge[0], dim=0, dim_size=sum(Natom))\n",
    "            \n",
    "            # transform the message using UpdateMLP, and add as residual connection\n",
    "            h += conv[\"update_mlp\"](agg_msg)\n",
    "        \n",
    "        readout = self.readout(h)\n",
    "        # readout for each individual graph in the batch\n",
    "        readout_split = torch.split(readout, Natom)\n",
    "        output = torch.stack(\n",
    "            [split.sum(0) for split in readout_split],\n",
    "            dim=0\n",
    "            )\n",
    "        \n",
    "        ################ Code #################\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "See if your GNN has the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0183]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node input\n",
    "AtomicNum_orig = torch.LongTensor([6, 6, 8, 7])\n",
    "# edge input \n",
    "Edge_orig = torch.LongTensor([[0, 0, 1, 2, 3, 0], [1, 2, 0, 0, 0, 3]] )\n",
    "\n",
    "model = GNN(n_convs=4, n_embed=128)\n",
    "model(AtomicNum_orig, Edge_orig, [len(AtomicNum_orig)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PmypwqSlu27Z",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 1.4 Verify that your GNN preserves permutational invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3F7-dv8su27Z"
   },
   "outputs": [],
   "source": [
    "def permute_graph(z, a, perm):\n",
    "    \"\"\"\n",
    "    Permutes the order of nodes in a molecular graph.\n",
    "\n",
    "    Args: \n",
    "        z(np.array): atomic number array\n",
    "        a(np.array): edge index pairs \n",
    "\n",
    "    Return: \n",
    "        (np.array, np.array): permuted atomic number, and edge list \n",
    "    \"\"\"\n",
    "    \n",
    "    z = np.array(z)\n",
    "    perm = np.array(perm)\n",
    "    assert len(perm) == len(z)\n",
    "    \n",
    "    z_perm = z[perm]\n",
    "    a_perm = np.zeros(a.shape).astype(int)\n",
    "    \n",
    "    for i, edge in enumerate(a):\n",
    "        for j in range(len(edge)):\n",
    "            a_perm[i, j] = np.where(perm==edge[j])[0]\n",
    "    return z_perm, a_perm\n",
    "\n",
    "# node input\n",
    "AtomicNum_orig = np.array([6, 6, 8, 7])\n",
    "# edge input \n",
    "Edge_orig = np.array([[0, 0, 1, 2, 3, 0], [1, 2, 0, 0, 0, 3]] )\n",
    "# generate permutations\n",
    "permutation = list(itertools.permutations([0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bulr_8wadVsN",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Test your model on a permuted graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "1t0AE5KndVsN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: -0.75114 for permutation: (0, 1, 2, 3)\n",
      "model output: -0.75114 for permutation: (0, 1, 3, 2)\n",
      "model output: -0.75114 for permutation: (0, 2, 1, 3)\n",
      "model output: -0.75114 for permutation: (0, 2, 3, 1)\n",
      "model output: -0.75114 for permutation: (0, 3, 1, 2)\n",
      "model output: -0.75114 for permutation: (0, 3, 2, 1)\n",
      "model output: -0.75114 for permutation: (1, 0, 2, 3)\n",
      "model output: -0.75114 for permutation: (1, 0, 3, 2)\n",
      "model output: -0.75114 for permutation: (1, 2, 0, 3)\n",
      "model output: -0.75114 for permutation: (1, 2, 3, 0)\n",
      "model output: -0.75114 for permutation: (1, 3, 0, 2)\n",
      "model output: -0.75114 for permutation: (1, 3, 2, 0)\n",
      "model output: -0.75114 for permutation: (2, 0, 1, 3)\n",
      "model output: -0.75114 for permutation: (2, 0, 3, 1)\n",
      "model output: -0.75114 for permutation: (2, 1, 0, 3)\n",
      "model output: -0.75114 for permutation: (2, 1, 3, 0)\n",
      "model output: -0.75114 for permutation: (2, 3, 0, 1)\n",
      "model output: -0.75114 for permutation: (2, 3, 1, 0)\n",
      "model output: -0.75114 for permutation: (3, 0, 1, 2)\n",
      "model output: -0.75114 for permutation: (3, 0, 2, 1)\n",
      "model output: -0.75114 for permutation: (3, 1, 0, 2)\n",
      "model output: -0.75114 for permutation: (3, 1, 2, 0)\n",
      "model output: -0.75114 for permutation: (3, 2, 0, 1)\n",
      "model output: -0.75114 for permutation: (3, 2, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "################ Code #################\n",
    "\n",
    "device = 0\n",
    "model = GNN(n_convs=4, n_embed=128).to(device)\n",
    "model.eval()\n",
    "\n",
    "for perm in permutation:\n",
    "    z_perm, a_perm = permute_graph(AtomicNum_orig, Edge_orig, perm)\n",
    "    z_perm = torch.LongTensor(z_perm).to(device)\n",
    "    a_perm = torch.LongTensor(a_perm).to(device)\n",
    "    output = model(z_perm, a_perm, [len(z_perm)]).detach().cpu().item()\n",
    "    print(\"model output: {:.5f} for permutation: {}\".format(output, perm)) \n",
    "    \n",
    "################ Code #################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b5KEswY8u27a",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 1.5  Train and test your GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MMgcJzzzu27a"
   },
   "outputs": [],
   "source": [
    "def loop(model, optimizer, loader, epoch, evaluation=False, device=\"cpu\"):\n",
    "    if evaluation:\n",
    "        model.eval()\n",
    "        mode = \"eval\"\n",
    "    else:\n",
    "        model.train()\n",
    "        mode = \"train\"\n",
    "    batch_losses = []\n",
    "    \n",
    "    # Define tqdm progress bar \n",
    "    tqdm_data = tqdm(loader, position=0, leave=True, desc=\"{} (epoch #{})\".format(mode, epoch))\n",
    "    \n",
    "    for data in tqdm_data:\n",
    "        AtomicNumber, Edge, Natom, y = data \n",
    "        AtomicNumber = AtomicNumber.to(device)\n",
    "        Edge = Edge.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # make predictions \n",
    "        pred = model(AtomicNumber, Edge, Natom)\n",
    "        \n",
    "        # define loss \n",
    "        loss = (pred - y).pow(2).mean()  \n",
    "        \n",
    "        if not evaluation:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        postfix = [\"batch loss={:.3f}\".format(loss.item()) , \n",
    "                   \"avg. loss={:.3f}\".format(np.array(batch_losses).mean())]\n",
    "        \n",
    "        tqdm_data.set_postfix_str(\" \".join(postfix))\n",
    "    \n",
    "    return np.array(batch_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "id": "8rjYSawwu27a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #0): 100%|███████████████████████████████████████████| 46/46 [00:01<00:00, 27.84it/s, batch loss=371.967 avg. loss=394235.262]\n",
      "eval (epoch #0): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.90it/s, batch loss=513.560 avg. loss=1480.859]\n",
      "train (epoch #1): 100%|███████████████████████████████████████████████| 46/46 [00:01<00:00, 28.12it/s, batch loss=66.744 avg. loss=359.314]\n",
      "eval (epoch #1): 100%|█████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.18it/s, batch loss=760.757 avg. loss=969.005]\n",
      "train (epoch #2): 100%|███████████████████████████████████████████████| 46/46 [00:01<00:00, 27.16it/s, batch loss=86.766 avg. loss=426.013]\n",
      "eval (epoch #2): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 64.74it/s, batch loss=714.168 avg. loss=1023.898]\n",
      "train (epoch #3): 100%|███████████████████████████████████████████████| 46/46 [00:01<00:00, 27.48it/s, batch loss=72.857 avg. loss=363.435]\n",
      "eval (epoch #3): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 64.83it/s, batch loss=1369.496 avg. loss=416.992]\n",
      "train (epoch #4): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 28.02it/s, batch loss=245.806 avg. loss=437.711]\n",
      "eval (epoch #4): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.67it/s, batch loss=1898.629 avg. loss=378.292]\n",
      "train (epoch #5): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 27.64it/s, batch loss=432.642 avg. loss=478.042]\n",
      "eval (epoch #5): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.11it/s, batch loss=1965.853 avg. loss=386.250]\n",
      "train (epoch #6): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 28.35it/s, batch loss=438.447 avg. loss=409.532]\n",
      "eval (epoch #6): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.04it/s, batch loss=1735.503 avg. loss=353.743]\n",
      "train (epoch #7): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 27.37it/s, batch loss=343.660 avg. loss=320.977]\n",
      "eval (epoch #7): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.93it/s, batch loss=1471.118 avg. loss=377.736]\n",
      "train (epoch #8): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 28.42it/s, batch loss=289.023 avg. loss=270.231]\n",
      "eval (epoch #8): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.82it/s, batch loss=1367.810 avg. loss=405.153]\n",
      "train (epoch #9): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 28.28it/s, batch loss=287.352 avg. loss=250.102]\n",
      "eval (epoch #9): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 70.45it/s, batch loss=1376.107 avg. loss=396.406]\n",
      "train (epoch #10): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.95it/s, batch loss=343.307 avg. loss=236.171]\n",
      "eval (epoch #10): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.78it/s, batch loss=1451.559 avg. loss=366.129]\n",
      "train (epoch #11): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.59it/s, batch loss=433.294 avg. loss=219.393]\n",
      "eval (epoch #11): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.17it/s, batch loss=1503.801 avg. loss=347.569]\n",
      "train (epoch #12): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.02it/s, batch loss=495.628 avg. loss=201.833]\n",
      "eval (epoch #12): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.18it/s, batch loss=1444.735 avg. loss=351.202]\n",
      "train (epoch #13): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.32it/s, batch loss=520.591 avg. loss=193.689]\n",
      "eval (epoch #13): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 28.81it/s, batch loss=1329.263 avg. loss=373.240]\n",
      "train (epoch #14): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.89it/s, batch loss=513.782 avg. loss=193.064]\n",
      "eval (epoch #14): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.23it/s, batch loss=1190.303 avg. loss=418.475]\n",
      "train (epoch #15): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.96it/s, batch loss=473.986 avg. loss=195.945]\n",
      "eval (epoch #15): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.40it/s, batch loss=1037.353 avg. loss=495.890]\n",
      "train (epoch #16): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.04it/s, batch loss=406.863 avg. loss=201.714]\n",
      "eval (epoch #16): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.15it/s, batch loss=887.057 avg. loss=605.149]\n",
      "train (epoch #17): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.81it/s, batch loss=548.230 avg. loss=302.212]\n",
      "eval (epoch #17): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.68it/s, batch loss=1195.064 avg. loss=373.403]\n",
      "train (epoch #18): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.66it/s, batch loss=337.679 avg. loss=157.492]\n",
      "eval (epoch #18): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.47it/s, batch loss=815.180 avg. loss=648.561]\n",
      "train (epoch #19): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.24it/s, batch loss=277.060 avg. loss=194.114]\n",
      "eval (epoch #19): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.25it/s, batch loss=772.250 avg. loss=682.877]\n",
      "train (epoch #20): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.64it/s, batch loss=255.779 avg. loss=184.369]\n",
      "eval (epoch #20): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.52it/s, batch loss=769.934 avg. loss=669.317]\n",
      "train (epoch #21): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.23it/s, batch loss=243.503 avg. loss=170.942]\n",
      "eval (epoch #21): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 70.01it/s, batch loss=779.709 avg. loss=641.971]\n",
      "train (epoch #22): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.18it/s, batch loss=240.409 avg. loss=158.612]\n",
      "eval (epoch #22): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 70.82it/s, batch loss=797.566 avg. loss=608.602]\n",
      "train (epoch #23): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.81it/s, batch loss=241.408 avg. loss=148.528]\n",
      "eval (epoch #23): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.80it/s, batch loss=816.307 avg. loss=577.902]\n",
      "train (epoch #24): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 33.47it/s, batch loss=241.420 avg. loss=141.711]\n",
      "eval (epoch #24): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.79it/s, batch loss=833.280 avg. loss=552.044]\n",
      "train (epoch #25): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.27it/s, batch loss=239.758 avg. loss=137.560]\n",
      "eval (epoch #25): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.91it/s, batch loss=848.088 avg. loss=530.928]\n",
      "train (epoch #26): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 31.16it/s, batch loss=234.795 avg. loss=136.248]\n",
      "eval (epoch #26): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 68.55it/s, batch loss=864.337 avg. loss=511.430]\n",
      "train (epoch #27): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.16it/s, batch loss=226.733 avg. loss=137.337]\n",
      "eval (epoch #27): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 68.13it/s, batch loss=884.744 avg. loss=491.138]\n",
      "train (epoch #28): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.86it/s, batch loss=216.723 avg. loss=139.962]\n",
      "eval (epoch #28): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.62it/s, batch loss=903.372 avg. loss=474.787]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #29): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.01it/s, batch loss=206.288 avg. loss=145.751]\n",
      "eval (epoch #29): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.45it/s, batch loss=930.709 avg. loss=452.924]\n",
      "train (epoch #30): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 31.30it/s, batch loss=194.642 avg. loss=152.318]\n",
      "eval (epoch #30): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 61.44it/s, batch loss=959.604 avg. loss=432.696]\n",
      "train (epoch #31): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.67it/s, batch loss=180.308 avg. loss=161.819]\n",
      "eval (epoch #31): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.77it/s, batch loss=985.111 avg. loss=417.769]\n",
      "train (epoch #32): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.87it/s, batch loss=168.875 avg. loss=173.245]\n",
      "eval (epoch #32): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.59it/s, batch loss=1021.271 avg. loss=398.013]\n",
      "train (epoch #33): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 31.48it/s, batch loss=153.363 avg. loss=187.596]\n",
      "eval (epoch #33): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.20it/s, batch loss=1048.922 avg. loss=385.852]\n",
      "train (epoch #34): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 27.32it/s, batch loss=136.575 avg. loss=205.582]\n",
      "eval (epoch #34): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 60.86it/s, batch loss=1067.249 avg. loss=378.858]\n",
      "train (epoch #35): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.59it/s, batch loss=112.620 avg. loss=228.701]\n",
      "eval (epoch #35): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.16it/s, batch loss=1057.406 avg. loss=389.223]\n",
      "train (epoch #36): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 31.59it/s, batch loss=91.565 avg. loss=255.604]\n",
      "eval (epoch #36): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.32it/s, batch loss=1017.494 avg. loss=418.693]\n",
      "train (epoch #37): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 31.76it/s, batch loss=71.650 avg. loss=290.955]\n",
      "eval (epoch #37): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 65.90it/s, batch loss=939.415 avg. loss=481.057]\n",
      "train (epoch #38): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 30.01it/s, batch loss=60.508 avg. loss=338.166]\n",
      "eval (epoch #38): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.96it/s, batch loss=820.878 avg. loss=592.225]\n",
      "train (epoch #39): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 29.77it/s, batch loss=62.460 avg. loss=404.478]\n",
      "eval (epoch #39): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.76it/s, batch loss=637.490 avg. loss=838.604]\n",
      "train (epoch #40): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 29.78it/s, batch loss=74.810 avg. loss=519.786]\n",
      "eval (epoch #40): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.16it/s, batch loss=372.528 avg. loss=1452.117]\n",
      "train (epoch #41): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 29.65it/s, batch loss=78.541 avg. loss=705.933]\n",
      "eval (epoch #41): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.96it/s, batch loss=237.966 avg. loss=1949.479]\n",
      "train (epoch #42): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.71it/s, batch loss=713.116 avg. loss=737.236]\n",
      "eval (epoch #42): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.17it/s, batch loss=772.220 avg. loss=567.729]\n",
      "train (epoch #43): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.99it/s, batch loss=751.523 avg. loss=321.029]\n",
      "eval (epoch #43): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.10it/s, batch loss=1191.061 avg. loss=291.733]\n",
      "train (epoch #44): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.10it/s, batch loss=565.228 avg. loss=165.113]\n",
      "eval (epoch #44): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 28.99it/s, batch loss=1117.829 avg. loss=312.731]\n",
      "train (epoch #45): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.67it/s, batch loss=481.886 avg. loss=136.704]\n",
      "eval (epoch #45): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.71it/s, batch loss=1062.463 avg. loss=333.718]\n",
      "train (epoch #46): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.00it/s, batch loss=430.382 avg. loss=123.657]\n",
      "eval (epoch #46): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.86it/s, batch loss=1034.505 avg. loss=343.089]\n",
      "train (epoch #47): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.86it/s, batch loss=398.404 avg. loss=115.473]\n",
      "eval (epoch #47): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.30it/s, batch loss=1030.320 avg. loss=339.156]\n",
      "train (epoch #48): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.86it/s, batch loss=380.683 avg. loss=110.538]\n",
      "eval (epoch #48): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.58it/s, batch loss=1034.006 avg. loss=330.869]\n",
      "train (epoch #49): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.61it/s, batch loss=372.319 avg. loss=107.836]\n",
      "eval (epoch #49): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.45it/s, batch loss=1038.597 avg. loss=322.109]\n",
      "train (epoch #50): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.38it/s, batch loss=367.993 avg. loss=104.996]\n",
      "eval (epoch #50): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.09it/s, batch loss=1003.155 avg. loss=331.092]\n",
      "train (epoch #51): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 31.90it/s, batch loss=375.586 avg. loss=104.989]\n",
      "eval (epoch #51): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.15it/s, batch loss=1048.108 avg. loss=306.559]\n",
      "train (epoch #52): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.80it/s, batch loss=380.426 avg. loss=103.903]\n",
      "eval (epoch #52): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.19it/s, batch loss=1053.908 avg. loss=299.998]\n",
      "train (epoch #53): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.46it/s, batch loss=388.237 avg. loss=103.766]\n",
      "eval (epoch #53): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 70.48it/s, batch loss=1062.817 avg. loss=292.542]\n",
      "train (epoch #54): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.00it/s, batch loss=396.716 avg. loss=104.726]\n",
      "eval (epoch #54): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.52it/s, batch loss=1068.631 avg. loss=288.126]\n",
      "train (epoch #55): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.44it/s, batch loss=399.131 avg. loss=106.324]\n",
      "eval (epoch #55): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.74it/s, batch loss=1066.957 avg. loss=287.280]\n",
      "train (epoch #56): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.00it/s, batch loss=398.702 avg. loss=108.646]\n",
      "eval (epoch #56): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.10it/s, batch loss=1060.237 avg. loss=289.776]\n",
      "train (epoch #57): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.01it/s, batch loss=387.333 avg. loss=111.590]\n",
      "eval (epoch #57): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.94it/s, batch loss=1044.971 avg. loss=297.239]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #58): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.28it/s, batch loss=368.309 avg. loss=114.554]\n",
      "eval (epoch #58): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.47it/s, batch loss=1021.269 avg. loss=309.919]\n",
      "train (epoch #59): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 26.75it/s, batch loss=342.923 avg. loss=117.262]\n",
      "eval (epoch #59): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.11it/s, batch loss=994.509 avg. loss=327.796]\n",
      "train (epoch #60): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 27.41it/s, batch loss=316.107 avg. loss=120.119]\n",
      "eval (epoch #60): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 65.57it/s, batch loss=959.866 avg. loss=353.101]\n",
      "train (epoch #61): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.56it/s, batch loss=288.279 avg. loss=123.288]\n",
      "eval (epoch #61): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 69.45it/s, batch loss=924.023 avg. loss=383.502]\n",
      "train (epoch #62): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.17it/s, batch loss=263.690 avg. loss=128.064]\n",
      "eval (epoch #62): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.06it/s, batch loss=892.720 avg. loss=416.775]\n",
      "train (epoch #63): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.92it/s, batch loss=235.620 avg. loss=133.530]\n",
      "eval (epoch #63): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.12it/s, batch loss=847.753 avg. loss=463.524]\n",
      "train (epoch #64): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 31.69it/s, batch loss=211.910 avg. loss=140.469]\n",
      "eval (epoch #64): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 68.73it/s, batch loss=803.956 avg. loss=514.974]\n",
      "train (epoch #65): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.92it/s, batch loss=190.667 avg. loss=147.764]\n",
      "eval (epoch #65): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.54it/s, batch loss=763.995 avg. loss=566.397]\n",
      "train (epoch #66): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.65it/s, batch loss=175.734 avg. loss=155.838]\n",
      "eval (epoch #66): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 68.48it/s, batch loss=737.688 avg. loss=607.790]\n",
      "train (epoch #67): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.21it/s, batch loss=167.767 avg. loss=163.460]\n",
      "eval (epoch #67): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 58.81it/s, batch loss=719.831 avg. loss=641.675]\n",
      "train (epoch #68): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.33it/s, batch loss=167.245 avg. loss=169.242]\n",
      "eval (epoch #68): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 27.82it/s, batch loss=703.774 avg. loss=671.748]\n",
      "train (epoch #69): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.18it/s, batch loss=171.732 avg. loss=173.517]\n",
      "eval (epoch #69): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.02it/s, batch loss=697.570 avg. loss=685.900]\n",
      "train (epoch #70): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 27.83it/s, batch loss=176.681 avg. loss=175.591]\n",
      "eval (epoch #70): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 64.28it/s, batch loss=690.727 avg. loss=702.549]\n",
      "train (epoch #71): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.57it/s, batch loss=183.643 avg. loss=176.728]\n",
      "eval (epoch #71): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 63.73it/s, batch loss=684.784 avg. loss=714.612]\n",
      "train (epoch #72): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.51it/s, batch loss=188.010 avg. loss=175.372]\n",
      "eval (epoch #72): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 59.97it/s, batch loss=683.999 avg. loss=719.355]\n",
      "train (epoch #73): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.58it/s, batch loss=196.457 avg. loss=172.754]\n",
      "eval (epoch #73): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 62.87it/s, batch loss=684.738 avg. loss=718.184]\n",
      "train (epoch #74): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.79it/s, batch loss=199.816 avg. loss=171.262]\n",
      "eval (epoch #74): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 65.23it/s, batch loss=681.293 avg. loss=723.878]\n",
      "train (epoch #75): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.05it/s, batch loss=209.408 avg. loss=168.725]\n",
      "eval (epoch #75): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 59.54it/s, batch loss=678.250 avg. loss=725.136]\n",
      "train (epoch #76): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.95it/s, batch loss=213.829 avg. loss=164.315]\n",
      "eval (epoch #76): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 57.02it/s, batch loss=680.043 avg. loss=721.727]\n",
      "train (epoch #77): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 26.45it/s, batch loss=218.324 avg. loss=159.707]\n",
      "eval (epoch #77): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 61.68it/s, batch loss=675.798 avg. loss=726.430]\n",
      "train (epoch #78): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.69it/s, batch loss=219.670 avg. loss=157.274]\n",
      "eval (epoch #78): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 61.63it/s, batch loss=676.979 avg. loss=722.077]\n",
      "train (epoch #79): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.64it/s, batch loss=222.623 avg. loss=151.953]\n",
      "eval (epoch #79): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 60.74it/s, batch loss=688.343 avg. loss=702.491]\n",
      "train (epoch #80): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.29it/s, batch loss=231.423 avg. loss=148.652]\n",
      "eval (epoch #80): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 63.95it/s, batch loss=688.461 avg. loss=692.655]\n",
      "train (epoch #81): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.53it/s, batch loss=243.478 avg. loss=145.808]\n",
      "eval (epoch #81): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 65.09it/s, batch loss=700.781 avg. loss=669.110]\n",
      "train (epoch #82): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.55it/s, batch loss=245.630 avg. loss=141.881]\n",
      "eval (epoch #82): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.12it/s, batch loss=708.077 avg. loss=651.710]\n",
      "train (epoch #83): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 32.72it/s, batch loss=259.104 avg. loss=138.116]\n",
      "eval (epoch #83): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 69.41it/s, batch loss=706.512 avg. loss=640.868]\n",
      "train (epoch #84): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.65it/s, batch loss=274.728 avg. loss=136.297]\n",
      "eval (epoch #84): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.27it/s, batch loss=712.205 avg. loss=620.711]\n",
      "train (epoch #85): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.69it/s, batch loss=304.083 avg. loss=136.900]\n",
      "eval (epoch #85): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.99it/s, batch loss=714.258 avg. loss=603.304]\n",
      "train (epoch #86): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.51it/s, batch loss=327.364 avg. loss=137.428]\n",
      "eval (epoch #86): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.94it/s, batch loss=714.965 avg. loss=590.101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #87): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.93it/s, batch loss=360.666 avg. loss=141.189]\n",
      "eval (epoch #87): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.70it/s, batch loss=707.137 avg. loss=580.075]\n",
      "train (epoch #88): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.54it/s, batch loss=399.917 avg. loss=146.458]\n",
      "eval (epoch #88): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.42it/s, batch loss=704.927 avg. loss=568.386]\n",
      "train (epoch #89): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.67it/s, batch loss=444.947 avg. loss=154.730]\n",
      "eval (epoch #89): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.59it/s, batch loss=700.901 avg. loss=556.659]\n",
      "train (epoch #90): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 27.42it/s, batch loss=498.615 avg. loss=163.970]\n",
      "eval (epoch #90): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.12it/s, batch loss=704.342 avg. loss=536.836]\n",
      "train (epoch #91): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.97it/s, batch loss=551.243 avg. loss=173.652]\n",
      "eval (epoch #91): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.15it/s, batch loss=746.438 avg. loss=480.243]\n",
      "train (epoch #92): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 32.00it/s, batch loss=569.580 avg. loss=171.322]\n",
      "eval (epoch #92): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.20it/s, batch loss=814.943 avg. loss=417.076]\n",
      "train (epoch #93): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 32.08it/s, batch loss=514.159 avg. loss=149.326]\n",
      "eval (epoch #93): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.74it/s, batch loss=915.971 avg. loss=352.662]\n",
      "train (epoch #94): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.20it/s, batch loss=387.561 avg. loss=126.537]\n",
      "eval (epoch #94): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 70.93it/s, batch loss=1065.030 avg. loss=300.392]\n",
      "train (epoch #95): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 28.58it/s, batch loss=225.182 avg. loss=172.195]\n",
      "eval (epoch #95): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.54it/s, batch loss=1262.668 avg. loss=273.922]\n",
      "train (epoch #96): 100%|██████████████████████████████████████████████| 46/46 [00:01<00:00, 29.67it/s, batch loss=80.705 avg. loss=410.377]\n",
      "eval (epoch #96): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.14it/s, batch loss=964.988 avg. loss=457.252]\n",
      "train (epoch #97): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.52it/s, batch loss=298.001 avg. loss=546.175]\n",
      "eval (epoch #97): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 71.10it/s, batch loss=458.013 avg. loss=1057.493]\n",
      "train (epoch #98): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.12it/s, batch loss=215.467 avg. loss=159.549]\n",
      "eval (epoch #98): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 67.47it/s, batch loss=573.730 avg. loss=788.808]\n",
      "train (epoch #99): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.71it/s, batch loss=242.560 avg. loss=127.329]\n",
      "eval (epoch #99): 100%|████████████████████████████████████████████████| 7/7 [00:00<00:00, 66.94it/s, batch loss=604.978 avg. loss=728.584]\n",
      "train (epoch #100): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.18it/s, batch loss=241.531 avg. loss=124.309]\n",
      "eval (epoch #100): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.70it/s, batch loss=597.737 avg. loss=737.063]\n",
      "train (epoch #101): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.22it/s, batch loss=230.442 avg. loss=122.505]\n",
      "eval (epoch #101): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.19it/s, batch loss=581.510 avg. loss=756.901]\n",
      "train (epoch #102): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.73it/s, batch loss=223.975 avg. loss=120.579]\n",
      "eval (epoch #102): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.30it/s, batch loss=573.733 avg. loss=761.000]\n",
      "train (epoch #103): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 26.96it/s, batch loss=213.758 avg. loss=116.894]\n",
      "eval (epoch #103): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.79it/s, batch loss=570.046 avg. loss=757.293]\n",
      "train (epoch #104): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.67it/s, batch loss=219.070 avg. loss=115.055]\n",
      "eval (epoch #104): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.74it/s, batch loss=568.474 avg. loss=748.073]\n",
      "train (epoch #105): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.50it/s, batch loss=225.053 avg. loss=112.980]\n",
      "eval (epoch #105): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.91it/s, batch loss=576.335 avg. loss=723.640]\n",
      "train (epoch #106): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.63it/s, batch loss=227.753 avg. loss=110.430]\n",
      "eval (epoch #106): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.90it/s, batch loss=574.431 avg. loss=717.169]\n",
      "train (epoch #107): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.78it/s, batch loss=247.193 avg. loss=109.561]\n",
      "eval (epoch #107): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.34it/s, batch loss=584.233 avg. loss=686.608]\n",
      "train (epoch #108): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.78it/s, batch loss=257.815 avg. loss=108.235]\n",
      "eval (epoch #108): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.65it/s, batch loss=589.526 avg. loss=667.247]\n",
      "train (epoch #109): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.58it/s, batch loss=275.445 avg. loss=106.613]\n",
      "eval (epoch #109): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.17it/s, batch loss=580.558 avg. loss=664.075]\n",
      "train (epoch #110): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.51it/s, batch loss=304.769 avg. loss=108.426]\n",
      "eval (epoch #110): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.11it/s, batch loss=578.936 avg. loss=654.285]\n",
      "train (epoch #111): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.78it/s, batch loss=329.932 avg. loss=112.740]\n",
      "eval (epoch #111): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.89it/s, batch loss=551.011 avg. loss=674.842]\n",
      "train (epoch #112): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 27.22it/s, batch loss=388.239 avg. loss=124.195]\n",
      "eval (epoch #112): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.10it/s, batch loss=524.173 avg. loss=697.483]\n",
      "train (epoch #113): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.17it/s, batch loss=472.321 avg. loss=148.672]\n",
      "eval (epoch #113): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.74it/s, batch loss=487.657 avg. loss=725.726]\n",
      "train (epoch #114): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.55it/s, batch loss=664.011 avg. loss=202.590]\n",
      "eval (epoch #114): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.18it/s, batch loss=500.590 avg. loss=661.490]\n",
      "train (epoch #115): 100%|███████████████████████████████████████████| 46/46 [00:01<00:00, 30.02it/s, batch loss=1002.508 avg. loss=290.293]\n",
      "eval (epoch #115): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.14it/s, batch loss=790.112 avg. loss=322.482]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #116): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.91it/s, batch loss=446.180 avg. loss=286.545]\n",
      "eval (epoch #116): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 65.17it/s, batch loss=1163.658 avg. loss=245.816]\n",
      "train (epoch #117): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.84it/s, batch loss=73.717 avg. loss=331.824]\n",
      "eval (epoch #117): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 66.21it/s, batch loss=421.960 avg. loss=1099.369]\n",
      "train (epoch #118): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.31it/s, batch loss=411.194 avg. loss=190.897]\n",
      "eval (epoch #118): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.37it/s, batch loss=533.775 avg. loss=707.061]\n",
      "train (epoch #119): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.37it/s, batch loss=343.467 avg. loss=169.131]\n",
      "eval (epoch #119): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.88it/s, batch loss=574.372 avg. loss=676.341]\n",
      "train (epoch #120): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.61it/s, batch loss=426.632 avg. loss=182.740]\n",
      "eval (epoch #120): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.28it/s, batch loss=639.496 avg. loss=581.816]\n",
      "train (epoch #121): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.13it/s, batch loss=491.444 avg. loss=200.660]\n",
      "eval (epoch #121): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.81it/s, batch loss=800.318 avg. loss=409.616]\n",
      "train (epoch #122): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.57it/s, batch loss=482.024 avg. loss=236.441]\n",
      "eval (epoch #122): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 62.46it/s, batch loss=904.335 avg. loss=328.485]\n",
      "train (epoch #123): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.10it/s, batch loss=342.799 avg. loss=218.205]\n",
      "eval (epoch #123): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 70.94it/s, batch loss=1014.745 avg. loss=276.270]\n",
      "train (epoch #124): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.52it/s, batch loss=175.505 avg. loss=185.374]\n",
      "eval (epoch #124): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.70it/s, batch loss=842.200 avg. loss=352.514]\n",
      "train (epoch #125): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.54it/s, batch loss=121.865 avg. loss=137.046]\n",
      "eval (epoch #125): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.27it/s, batch loss=673.092 avg. loss=493.952]\n",
      "train (epoch #126): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.89it/s, batch loss=103.491 avg. loss=117.819]\n",
      "eval (epoch #126): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.71it/s, batch loss=591.817 avg. loss=601.698]\n",
      "train (epoch #127): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.81it/s, batch loss=94.977 avg. loss=117.305]\n",
      "eval (epoch #127): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.61it/s, batch loss=544.621 avg. loss=684.748]\n",
      "train (epoch #128): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.19it/s, batch loss=93.143 avg. loss=119.217]\n",
      "eval (epoch #128): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.26it/s, batch loss=515.925 avg. loss=739.664]\n",
      "train (epoch #129): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.85it/s, batch loss=123.548 avg. loss=124.741]\n",
      "eval (epoch #129): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 62.43it/s, batch loss=408.363 avg. loss=943.036]\n",
      "train (epoch #130): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.55it/s, batch loss=125.897 avg. loss=180.041]\n",
      "eval (epoch #130): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.97it/s, batch loss=602.945 avg. loss=559.680]\n",
      "train (epoch #131): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.49it/s, batch loss=110.108 avg. loss=128.067]\n",
      "eval (epoch #131): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.53it/s, batch loss=471.435 avg. loss=837.186]\n",
      "train (epoch #132): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.59it/s, batch loss=141.037 avg. loss=120.129]\n",
      "eval (epoch #132): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.92it/s, batch loss=514.141 avg. loss=757.115]\n",
      "train (epoch #133): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.39it/s, batch loss=157.486 avg. loss=118.065]\n",
      "eval (epoch #133): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.35it/s, batch loss=505.938 avg. loss=777.106]\n",
      "train (epoch #134): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.17it/s, batch loss=173.681 avg. loss=121.972]\n",
      "eval (epoch #134): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.79it/s, batch loss=535.986 avg. loss=732.549]\n",
      "train (epoch #135): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.35it/s, batch loss=191.692 avg. loss=119.459]\n",
      "eval (epoch #135): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 29.19it/s, batch loss=553.609 avg. loss=694.299]\n",
      "train (epoch #136): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.38it/s, batch loss=162.501 avg. loss=120.765]\n",
      "eval (epoch #136): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.67it/s, batch loss=546.618 avg. loss=724.193]\n",
      "train (epoch #137): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.93it/s, batch loss=180.000 avg. loss=122.600]\n",
      "eval (epoch #137): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.79it/s, batch loss=559.930 avg. loss=698.710]\n",
      "train (epoch #138): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.97it/s, batch loss=163.013 avg. loss=121.328]\n",
      "eval (epoch #138): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.34it/s, batch loss=553.046 avg. loss=718.461]\n",
      "train (epoch #139): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 31.38it/s, batch loss=168.001 avg. loss=121.467]\n",
      "eval (epoch #139): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.47it/s, batch loss=543.528 avg. loss=724.013]\n",
      "train (epoch #140): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.23it/s, batch loss=133.131 avg. loss=117.436]\n",
      "eval (epoch #140): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.17it/s, batch loss=513.126 avg. loss=775.985]\n",
      "train (epoch #141): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.02it/s, batch loss=173.443 avg. loss=113.787]\n",
      "eval (epoch #141): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.51it/s, batch loss=546.497 avg. loss=706.872]\n",
      "train (epoch #142): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.78it/s, batch loss=161.670 avg. loss=109.369]\n",
      "eval (epoch #142): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.97it/s, batch loss=561.067 avg. loss=685.604]\n",
      "train (epoch #143): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.41it/s, batch loss=141.203 avg. loss=113.878]\n",
      "eval (epoch #143): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.92it/s, batch loss=516.181 avg. loss=773.410]\n",
      "train (epoch #144): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.17it/s, batch loss=150.309 avg. loss=110.701]\n",
      "eval (epoch #144): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 71.02it/s, batch loss=512.638 avg. loss=765.216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #145): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.95it/s, batch loss=194.741 avg. loss=107.776]\n",
      "eval (epoch #145): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.03it/s, batch loss=547.070 avg. loss=684.203]\n",
      "train (epoch #146): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 25.50it/s, batch loss=174.676 avg. loss=103.278]\n",
      "eval (epoch #146): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.86it/s, batch loss=576.458 avg. loss=642.683]\n",
      "train (epoch #147): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.81it/s, batch loss=133.158 avg. loss=100.858]\n",
      "eval (epoch #147): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.63it/s, batch loss=565.456 avg. loss=669.327]\n",
      "train (epoch #148): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 31.96it/s, batch loss=114.232 avg. loss=112.311]\n",
      "eval (epoch #148): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.63it/s, batch loss=520.147 avg. loss=747.118]\n",
      "train (epoch #149): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 31.22it/s, batch loss=137.418 avg. loss=109.337]\n",
      "eval (epoch #149): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.31it/s, batch loss=511.436 avg. loss=746.863]\n",
      "train (epoch #150): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 27.89it/s, batch loss=152.688 avg. loss=104.317]\n",
      "eval (epoch #150): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.80it/s, batch loss=441.363 avg. loss=858.719]\n",
      "train (epoch #151): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.28it/s, batch loss=273.004 avg. loss=124.266]\n",
      "eval (epoch #151): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.04it/s, batch loss=420.220 avg. loss=846.209]\n",
      "train (epoch #152): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.82it/s, batch loss=519.188 avg. loss=199.277]\n",
      "eval (epoch #152): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.33it/s, batch loss=521.980 avg. loss=615.962]\n",
      "train (epoch #153): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.26it/s, batch loss=296.038 avg. loss=208.958]\n",
      "eval (epoch #153): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.06it/s, batch loss=514.213 avg. loss=635.201]\n",
      "train (epoch #154): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.87it/s, batch loss=807.088 avg. loss=254.407]\n",
      "eval (epoch #154): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 65.79it/s, batch loss=1306.458 avg. loss=245.745]\n",
      "train (epoch #155): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 26.74it/s, batch loss=63.686 avg. loss=238.051]\n",
      "eval (epoch #155): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.99it/s, batch loss=600.744 avg. loss=717.245]\n",
      "train (epoch #156): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.10it/s, batch loss=447.065 avg. loss=204.573]\n",
      "eval (epoch #156): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.61it/s, batch loss=853.725 avg. loss=346.614]\n",
      "train (epoch #157): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 27.44it/s, batch loss=264.108 avg. loss=134.286]\n",
      "eval (epoch #157): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.13it/s, batch loss=895.859 avg. loss=344.586]\n",
      "train (epoch #158): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.89it/s, batch loss=174.259 avg. loss=157.535]\n",
      "eval (epoch #158): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.43it/s, batch loss=893.361 avg. loss=339.904]\n",
      "train (epoch #159): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.06it/s, batch loss=111.593 avg. loss=142.765]\n",
      "eval (epoch #159): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.58it/s, batch loss=706.988 avg. loss=505.811]\n",
      "train (epoch #160): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.14it/s, batch loss=113.874 avg. loss=118.453]\n",
      "eval (epoch #160): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 70.65it/s, batch loss=701.950 avg. loss=502.430]\n",
      "train (epoch #161): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.27it/s, batch loss=95.747 avg. loss=118.798]\n",
      "eval (epoch #161): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.31it/s, batch loss=648.590 avg. loss=582.813]\n",
      "train (epoch #162): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 30.13it/s, batch loss=86.860 avg. loss=109.186]\n",
      "eval (epoch #162): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.93it/s, batch loss=600.090 avg. loss=672.899]\n",
      "train (epoch #163): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.83it/s, batch loss=118.030 avg. loss=118.240]\n",
      "eval (epoch #163): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 67.58it/s, batch loss=680.696 avg. loss=530.836]\n",
      "train (epoch #164): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.45it/s, batch loss=81.817 avg. loss=106.447]\n",
      "eval (epoch #164): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.49it/s, batch loss=616.219 avg. loss=621.255]\n",
      "train (epoch #165): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.82it/s, batch loss=117.068 avg. loss=109.696]\n",
      "eval (epoch #165): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.63it/s, batch loss=668.329 avg. loss=536.819]\n",
      "train (epoch #166): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 27.41it/s, batch loss=83.265 avg. loss=116.133]\n",
      "eval (epoch #166): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 69.27it/s, batch loss=607.627 avg. loss=652.959]\n",
      "train (epoch #167): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.63it/s, batch loss=101.586 avg. loss=117.812]\n",
      "eval (epoch #167): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.30it/s, batch loss=629.984 avg. loss=633.490]\n",
      "train (epoch #168): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.30it/s, batch loss=105.373 avg. loss=130.374]\n",
      "eval (epoch #168): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 65.52it/s, batch loss=632.541 avg. loss=657.573]\n",
      "train (epoch #169): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.38it/s, batch loss=138.685 avg. loss=140.418]\n",
      "eval (epoch #169): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 58.83it/s, batch loss=698.474 avg. loss=581.529]\n",
      "train (epoch #170): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.59it/s, batch loss=102.682 avg. loss=131.888]\n",
      "eval (epoch #170): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 66.81it/s, batch loss=615.216 avg. loss=708.270]\n",
      "train (epoch #171): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.82it/s, batch loss=195.698 avg. loss=139.740]\n",
      "eval (epoch #171): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 62.77it/s, batch loss=769.848 avg. loss=493.315]\n",
      "train (epoch #172): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.08it/s, batch loss=173.810 avg. loss=169.808]\n",
      "eval (epoch #172): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.73it/s, batch loss=738.034 avg. loss=568.631]\n",
      "train (epoch #173): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 31.24it/s, batch loss=88.882 avg. loss=149.316]\n",
      "eval (epoch #173): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.53it/s, batch loss=637.927 avg. loss=684.260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (epoch #174): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.53it/s, batch loss=314.263 avg. loss=172.820]\n",
      "eval (epoch #174): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 66.01it/s, batch loss=1014.165 avg. loss=315.777]\n",
      "train (epoch #175): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.14it/s, batch loss=63.029 avg. loss=224.795]\n",
      "eval (epoch #175): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 68.74it/s, batch loss=750.818 avg. loss=547.519]\n",
      "train (epoch #176): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.76it/s, batch loss=138.070 avg. loss=299.109]\n",
      "eval (epoch #176): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.63it/s, batch loss=860.313 avg. loss=431.032]\n",
      "train (epoch #177): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 30.54it/s, batch loss=456.906 avg. loss=207.108]\n",
      "eval (epoch #177): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 65.99it/s, batch loss=1591.593 avg. loss=297.404]\n",
      "train (epoch #178): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.64it/s, batch loss=167.570 avg. loss=352.608]\n",
      "eval (epoch #178): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 63.60it/s, batch loss=1850.031 avg. loss=392.157]\n",
      "train (epoch #179): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 31.63it/s, batch loss=206.099 avg. loss=252.248]\n",
      "eval (epoch #179): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 62.55it/s, batch loss=1440.365 avg. loss=267.404]\n",
      "train (epoch #180): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.10it/s, batch loss=352.353 avg. loss=346.790]\n",
      "eval (epoch #180): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 64.55it/s, batch loss=1320.470 avg. loss=248.926]\n",
      "train (epoch #181): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 27.53it/s, batch loss=211.017 avg. loss=122.258]\n",
      "eval (epoch #181): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 62.38it/s, batch loss=1201.013 avg. loss=261.959]\n",
      "train (epoch #182): 100%|█████████████████████████████████████████████| 46/46 [00:01<00:00, 29.17it/s, batch loss=67.628 avg. loss=225.467]\n",
      "eval (epoch #182): 100%|██████████████████████████████████████████████| 7/7 [00:00<00:00, 66.89it/s, batch loss=324.881 avg. loss=1214.575]\n",
      "train (epoch #183): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.75it/s, batch loss=257.254 avg. loss=268.404]\n",
      "eval (epoch #183): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.28it/s, batch loss=647.830 avg. loss=545.052]\n",
      "train (epoch #184): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.30it/s, batch loss=174.634 avg. loss=159.525]\n",
      "eval (epoch #184): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 62.39it/s, batch loss=630.206 avg. loss=519.117]\n",
      "train (epoch #185): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 28.78it/s, batch loss=253.575 avg. loss=136.015]\n",
      "eval (epoch #185): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 70.37it/s, batch loss=734.295 avg. loss=408.994]\n",
      "train (epoch #186): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 32.37it/s, batch loss=249.965 avg. loss=128.289]\n",
      "eval (epoch #186): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 64.43it/s, batch loss=748.744 avg. loss=390.343]\n",
      "train (epoch #187): 100%|████████████████████████████████████████████| 46/46 [00:01<00:00, 29.41it/s, batch loss=252.334 avg. loss=120.169]\n",
      "eval (epoch #187): 100%|███████████████████████████████████████████████| 7/7 [00:00<00:00, 63.39it/s, batch loss=830.577 avg. loss=309.975]\n",
      "train (epoch #188):  17%|███████▊                                     | 8/46 [00:00<00:01, 29.31it/s, batch loss=280.541 avg. loss=148.946]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119017/206195802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_119017/3094318655.py\u001b[0m in \u001b[0;36mloop\u001b[0;34m(model, optimizer, loader, epoch, evaluation, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from torch import optim\n",
    "\n",
    "# device = 0\n",
    "# model = GNN(n_convs=4, n_embed=128).to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50, verbose=True)\n",
    "\n",
    "# for epoch in range(500):    \n",
    "#     train_loss = loop(model, optimizer, train_loader, epoch, device=device)\n",
    "#     val_loss = loop(model, optimizer, val_loader, epoch, evaluation=True, device=device)\n",
    "    \n",
    "#     # save model \n",
    "#     if epoch % 20 == 0:\n",
    "#         torch.save(model.state_dict(), \"saved_models_part1/gcn_model_{}.pt\".format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Plot a scatter plot (predicted vs. true polarizabilities, training and test set) and losses during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119017/3551812669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtest_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_119017/3551812669.py\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(model, loader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAtomicNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNatom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_119017/2975162501.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, AtomicNum, Edge, Natom)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# send the messages to nodes, undirected graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# sum(Natom) is needed because we collated the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0magg_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEdge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNatom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                       \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEdge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNatom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_file = \"./saved_models_part1/gcn_model_480.pt\"\n",
    "model = GNN(n_convs=4, n_embed=128)\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "def get_predictions(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    preds = []\n",
    "    truth = []\n",
    "    \n",
    "    for data in loader:\n",
    "        AtomicNumber, Edge, Natom, y = data \n",
    "        AtomicNumber = AtomicNumber.to(device)\n",
    "        Edge = Edge.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        pred = model(AtomicNumber, Edge, Natom)\n",
    "        loss = (pred - y).pow(2).sum()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds.extend(pred.cpu())\n",
    "        truth.extend(y.cpu())\n",
    "    \n",
    "    return total_loss / len(loader), preds, truth\n",
    "    \n",
    "device = 0\n",
    "model.to(device)\n",
    "train_mse, train_preds, train_truth = get_predictions(model, train_loader, device=device)\n",
    "test_mse, test_preds, test_truth = get_predictions(model, test_loader, device=device)\n",
    "\n",
    "plt.scatter(train_truth, train_preds, color=\"c0\", label=f\"train (MSE: {train_mse:.5f})\")\n",
    "plt.scatter(test_truth, test_preds, color=\"c1\", label=f\"test (MSE: {test_mse:.5f})\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ps4_graphconv_solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
