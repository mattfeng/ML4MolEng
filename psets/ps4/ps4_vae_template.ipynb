{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:ps3]",
      "language": "python",
      "name": "conda-env-ps3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "ps4_vae_template.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPPFDi2nLDDN"
      },
      "source": [
        "#  <center> Problem Set 4 <center>\n",
        "<center> Spring 2021 <center>\n",
        "<center> 3.100/3.322, 10.402/10.602, 20.301/20.401 <center>\n",
        "<center> Due:10 pm ET on Thursday, Apr 22, 2021 <center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9wQfnRCLDDS"
      },
      "source": [
        "## Part 2 SMILES-VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0xzd3y7LDDT"
      },
      "source": [
        "First, Request a GPU by going to Edit/Notebook Settings/Hardward Accelerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do_6vp_ALDDT"
      },
      "source": [
        "# install RDKIT \n",
        "\n",
        "# This is a hack to install rdkit without needing to install anaconda which might take minutes \n",
        "# if you have anaconda installed, you can directly install rdkit from anaconda \n",
        "url = 'https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
        "!curl -L $url | tar xj lib\n",
        "!mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.7/dist-packages/\n",
        "\n",
        "x86 = '/usr/lib/x86_64-linux-gnu'\n",
        "!mv lib/*.so.* $x86/\n",
        "!ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1\n",
        "\n",
        "# Install tqdm progress bar \n",
        "!pip install tqdm "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jg-DK_WLDDU"
      },
      "source": [
        "# Optional: mount your google drive to save model and files \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "mydrive = '/content/drive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6znwa9MnLDDU"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from rdkit import RDLogger   \n",
        "RDLogger.DisableLog('rdApp.*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8x8c43LDDU"
      },
      "source": [
        "# Get data \n",
        "! wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps4/data/zinc_50k.csv\n",
        "    \n",
        "# Get pretrained VAE model \n",
        "! wget -O vae_checkpoint.pth https://github.com/wwang2/ML4MolEng/blob/master/psets/ps4/pretrained_checkpoints/vae-050-0.06.pth?raw=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "355HMSjvLDDV"
      },
      "source": [
        "### 1.1 One-hot encode SMILES strings into padded numerical vec-tors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhdMBRF3LDDV"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Character list for SMILES string\n",
        "moses_charset = ['2', 'o', 'C', 'I', 'O', 'H', 'n', 'N', '=', '+', '#', '-', 'c',\n",
        "                 'B', 'l', '7', 'r', 'S', 's', '4', '6', '[', '5', ']', 'F', '3', \n",
        "                 'P', '(', ')', '1', ' ']\n",
        "\n",
        "# Define encoder \n",
        "enc = preprocessing.LabelEncoder().fit(moses_charset)\n",
        "\n",
        "# Read data \n",
        "df = pd.read_csv(\"./zinc_50k.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fumu4UArLDDV"
      },
      "source": [
        "Encode SMILES string into padded categorial vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMF6gbLVLDDW"
      },
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Na-oiOLDDW"
      },
      "source": [
        "Make train/validation/test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP580LJHLDDW"
      },
      "source": [
        "################ Code #################\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UQEv61MLDDW"
      },
      "source": [
        "### 1.2 Implement the reparametrization trick for VAE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol5NTLLELDDW"
      },
      "source": [
        "# Molecular VAE model \n",
        "\n",
        "class MolVAE(nn.Module):\n",
        "    def __init__(self,  rnn_enc_hid_dim, enc_nconv,\n",
        "                         encoder_hid, z_dim, \n",
        "                         rnn_dec_hid_dim, dec_nconv, smiles_len, nchar\n",
        "                         ):\n",
        "        '''\n",
        "            SMILES VAE model \n",
        "            \n",
        "                rnn_enc_hid_dim: hidden dimension for the GRU encoder \n",
        "                enc_nconv: number of recurrent layers for the GRU decoder\n",
        "                encoder_hid: dimension of GUR encoder readout\n",
        "                z_dim: number of latent variable \n",
        "                rnn_dec_hid_dim: hidden dimension for the GRU decoder \n",
        "                dec_nconv: number of recurrent layers for the GRU decoder\n",
        "                smiles_len: total length of padded SMILES string \n",
        "                nchar: number of possible characters \n",
        "                \n",
        "        '''\n",
        "        \n",
        "        super(MolVAE, self).__init__()\n",
        "        \n",
        "        self.smiles_len = smiles_len\n",
        "        self.nchar = nchar\n",
        "        # Embedding layer\n",
        "        self.embed = nn.Embedding(self.nchar, rnn_enc_hid_dim)\n",
        "        # Encoding GRU\n",
        "        self.rnn_enc = nn.GRU(rnn_enc_hid_dim, rnn_enc_hid_dim, enc_nconv, batch_first=True)\n",
        "        # MLP to transfrom hidden output from Encoding GRU\n",
        "        self.mlp0 = nn.Linear(rnn_enc_hid_dim, encoder_hid)\n",
        "        # Network to parametrize mu\n",
        "        self.mu_network = nn.Linear(encoder_hid, z_dim)\n",
        "        # Network to parametrize log variance\n",
        "        self.logvar_network = nn.Linear(encoder_hid, z_dim)\n",
        "        # Decoding GRU\n",
        "        self.rnn_dec = nn.GRU(z_dim, rnn_dec_hid_dim, dec_nconv, batch_first=True)\n",
        "        # Output SMILES characters\n",
        "        self.readout = nn.Linear(rnn_dec_hid_dim, self.nchar)\n",
        "\n",
        "    def encode(self, x):\n",
        "        '''output mean and logVariance of the encoded SMILES'''\n",
        "        output, hn = self.rnn_enc(x)\n",
        "        h = F.relu(self.mlp0(hn[-1]))\n",
        "        return self.mu_network(h), self.logvar_network(h)\n",
        "    \n",
        "    def get_std(self, logvar):\n",
        "        '''transfrom log variance to standard deviation'''\n",
        "        ################ Code #################\n",
        "        \n",
        "        return logvar\n",
        "        ################ Code #################\n",
        "\n",
        "    def reparametrize(self, mu, std):\n",
        "        '''the reparametrization trick'''\n",
        "        if self.training:\n",
        "            ################ Code #################\n",
        "            \n",
        "            \n",
        "            return z\n",
        "           ################ Code ################# \n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        '''decoder to reconstruct latent variable back to SMILES'''\n",
        "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, self.smiles_len, 1)\n",
        "        out, h = self.rnn_dec(z)\n",
        "        out_reshape = out.contiguous().view(-1, out.size(-1))\n",
        "        \n",
        "        y0 = self.readout(out_reshape)\n",
        "        y = y0.contiguous().view(out.size(0), -1, y0.size(-1))\n",
        "        return y\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_embed = self.embed(x) # Get SMILES embedding \n",
        "        mu, logvar = self.encode(x_embed) # Encoding SMILES to latent representations \n",
        "        std = self.get_std(logvar) # tranfrom log variance to std.\n",
        "        z = self.reparametrize(mu, std) # reparametrization trick \n",
        "        smiles_recon = self.decode(z)  # reconstruct SMILES string \n",
        "        return smiles_recon, mu, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwyf09mALxZm"
      },
      "source": [
        "Sample a 1d Gaussian distribution with mean 0, std = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLvF-dGdLDDX"
      },
      "source": [
        "################ Code #################\n",
        "\n",
        "# sample = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lP9coMuLDDY"
      },
      "source": [
        "# Compare your sampling with N(0, 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "plt.hist(sample.detach().cpu().numpy(), density=True)\n",
        "\n",
        "# Plot a 1d unit Gaussian \n",
        "x_axis = np.arange(-7, 7, 0.001)\n",
        "plt.plot(x_axis, norm.pdf(x_axis,0,1)) # Mean = 0, SD = 1.\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WLmVkJKLDDY"
      },
      "source": [
        "### 1.3 Implement the SMILES VAE loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgkqLI_jLDDY"
      },
      "source": [
        "def loss_function(recon_x, x, mu, var):\n",
        "    ################ Code #################\n",
        "    L_recon = 0.0  # reconstruction loss \n",
        "    L_kl = 0.0 # KL loss\n",
        "    return L_recon, L_kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Svto16LDDZ"
      },
      "source": [
        "# Helper functions \n",
        "def index2smiles(mol_index, enc):\n",
        "    '''Transform Your An array of character index back to SMILES'''\n",
        "    smiles_charlist = enc.inverse_transform(mol_index)\n",
        "    smiles = ''.join(smiles_charlist).strip(\" \")\n",
        "    \n",
        "    return smiles\n",
        "\n",
        "def check_smiles_valid(smiles):\n",
        "    '''Check if SMILES string is valid'''\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        valid = True \n",
        "    else:\n",
        "        valid = False \n",
        "    return valid\n",
        "\n",
        "def sample_recon(model, epoch, dataloader, enc, n_sample=500):\n",
        "    '''Randomly sample from data loader to get reconstructed SMILES and test if it is valid'''\n",
        "    # evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    # Randomly select samples \n",
        "    random_mol = random.choices( range( len(dataloader.dataset) ), k=n_sample)\n",
        "    x_mol = train_loader.dataset.__getitem__(random_mol)[0]\n",
        "    x_mol = x_mol.to(device)\n",
        "    \n",
        "    # Get reconstructed Molecule \n",
        "    mol_recon, mu, logvar = model(x_mol)\n",
        "    mol_index = mol_recon.detach().cpu().numpy().argmax(-1).squeeze()\n",
        "    mol_orig = x_mol.detach().cpu().numpy()\n",
        "    \n",
        "    # Show the first reconstructed SMILES\n",
        "    print(\"epoch {} sample orig SMILES: {}\".format(epoch,  index2smiles(mol_orig[0], enc)))\n",
        "    print(\"epoch {} sample recon SMILES: {}\".format(epoch,  index2smiles(mol_index[0], enc)))\n",
        "    \n",
        "    valid_count = 0 \n",
        "    for indexed_smiles in mol_index:\n",
        "        smiles = index2smiles(indexed_smiles, enc)\n",
        "        valid = check_smiles_valid(smiles)\n",
        "        \n",
        "        if valid: \n",
        "            valid_count += 1\n",
        "    \n",
        "    print(\"{}/{} SMILES are valid\".format(valid_count, n_sample))\n",
        "\n",
        "def loop(model, loader, epoch, beta=0.05, evaluation=False):\n",
        "    '''\n",
        "        Train/test your VAE model\n",
        "    '''\n",
        "    \n",
        "    if evaluation:\n",
        "        model.eval()\n",
        "        mode = \"eval\"\n",
        "    else:\n",
        "        model.train()\n",
        "        mode = 'train'\n",
        "    batch_losses = []\n",
        "        \n",
        "    tqdm_data = tqdm(loader, position=0, leave=True, desc='{} (epoch #{})'.format(mode, epoch))\n",
        "    for data in tqdm_data:\n",
        "        \n",
        "        x = data[0].to(device)\n",
        "        recon_batch, mu, std = model(x)\n",
        "        loss_recon, loss_kl = loss_function(recon_batch, x, mu, std)\n",
        "        loss = loss_recon + beta * loss_kl     \n",
        "        \n",
        "        if not evaluation:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "        postfix = ['recon loss={:.3f}'.format(loss_recon.item()) ,\n",
        "                   'KL loss={:.3f}'.format(loss_kl.item()) ,\n",
        "                   'total loss={:.3f}'.format(loss.item()) , \n",
        "                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n",
        "        \n",
        "        tqdm_data.set_postfix_str(' '.join(postfix))\n",
        "    \n",
        "    return np.array(batch_losses).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k_6FrCpLDDZ"
      },
      "source": [
        "### 1.4  Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ6CG8DiLDDa"
      },
      "source": [
        "device = 0\n",
        "\n",
        "model = MolVAE(rnn_enc_hid_dim=367, enc_nconv=2, \n",
        "                     encoder_hid=512, z_dim=171, rnn_dec_hid_dim=512,\n",
        "                    dec_nconv=1, nchar=31, smiles_len=max_len)\n",
        "                      \n",
        "model = model.to(device)\n",
        "\n",
        "# load pretrained model \n",
        "model.load_state_dict(torch.load(\"./vae_checkpoint.pth\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgHPDig-LDDa"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=5e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IayKlIjoLDDa"
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    sample_recon(model, epoch, val_loader, enc)\n",
        "    train_loss = loop(model, train_loader, epoch)\n",
        "    val_loss = loop(model, val_loader, epoch, evaluation=True)\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # optional: save model \n",
        "#     if epoch % 15 == 0:\n",
        "#         torch.save(model.state_dict(),\n",
        "#                 './{}/vae-{:03d}-{:.2f}.pth'.format(mydrive, epoch, train_loss))\n",
        "        \n",
        "#         torch.save(optimizer.state_dict(),\n",
        "#             './{}/optim-{:03d}-{:.2f}.pth'.format(mydrive, epoch, train_loss))\n",
        "\n",
        "    if epoch == 0:\n",
        "        best_loss = train_loss.item()\n",
        "    else:\n",
        "        if train_loss.item() < best_loss:\n",
        "            best_loss = train_loss.item()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irPJVr5GLDDa"
      },
      "source": [
        "### 1.5 Sample new molecules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhHlUOxQLDDb"
      },
      "source": [
        "################ Code #################\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQAB517EfdSR"
      },
      "source": [
        "Visualize molecular line drawings for the molecules you generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3TIsR5OfOct"
      },
      "source": [
        "################ Code #################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}