{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ps4_graphconv_solutions.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:ps3]",
      "language": "python",
      "name": "conda-env-ps3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc_fzIDFu27D"
      },
      "source": [
        "#  <center> Problem Set 4 <center>\n",
        "<center> Spring 2021 <center>\n",
        "<center> 3.100/3.322, 10.402/10.602, 20.301/20.401 <center>\n",
        "<center> Due:10 pm ET on Thursday, Apr 22, 2021 <center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D86KaQiJu27R"
      },
      "source": [
        "## Part 2 Graph Convolutional Nets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9egPqYGu27S"
      },
      "source": [
        "### 1.1 Install and try out RDkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUVPzIPKvxPf"
      },
      "source": [
        "First, Request a GPU by going to Edit/Notebook Settings/Hardward Accelerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaqogUbau27S"
      },
      "source": [
        "# This is a hack to install rdkit without needing to install conda which might take minutes \n",
        "# if you have anaconda installed, you can install rdkit from anaconda \n",
        "url = 'https://anaconda.org/rdkit/rdkit/2018.09.1.0/download/linux-64/rdkit-2018.09.1.0-py36h71b666b_1.tar.bz2'\n",
        "!curl -L $url | tar xj lib\n",
        "!mv lib/python3.6/site-packages/rdkit /usr/local/lib/python3.7/dist-packages/\n",
        "\n",
        "x86 = '/usr/lib/x86_64-linux-gnu'\n",
        "!mv lib/*.so.* $x86/\n",
        "!ln -s $x86/libboost_python3-py36.so.1.65.1 $x86/libboost_python3.so.1.65.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh0SNwnEu27T"
      },
      "source": [
        "import numpy as np\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import Descriptors,Crippen\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch \n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "\n",
        "from rdkit import RDLogger   \n",
        "RDLogger.DisableLog('rdApp.*') # turn off RDKit warning message "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrooBdScu27T"
      },
      "source": [
        "# Optional: mount your google drive to save model and files \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "mydrive = '/content/drive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgZjTmmeu27T"
      },
      "source": [
        "### example \n",
        "# make a mol object \n",
        "dopamine_mol = Chem.MolFromSmiles(\"C1=CC(=C(C=C1CCN)O)O\") # Dopamine \n",
        "caffeine_mol = Chem.MolFromSmiles(\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\") # Caffeine "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4__JJvjju27U"
      },
      "source": [
        "# Arrange molecules in a grid image\n",
        "Draw.MolsToGridImage([dopamine_mol, caffeine_mol])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-pHcEc5dzJ2"
      },
      "source": [
        "Use RDKit to visualize molecule line drawings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As-wlFiOduUt"
      },
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vuVsOhYu27U"
      },
      "source": [
        "### 1.2 Construct molecular graph datasets and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADhhYCE6dVsF"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps4/data/qm9.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq0h_UJxu27V"
      },
      "source": [
        "# implement SMILES to graph function  \n",
        "def smiles2graph(smiles):\n",
        "    '''\n",
        "    Transfrom smiles into a list nodes (atomic number)\n",
        "    \n",
        "    Args: \n",
        "        smiles (str): SMILES strings\n",
        "    \n",
        "    return: \n",
        "        z(np.array), A (np.array): list of atomic numbers, adjancency matrix \n",
        "    '''\n",
        "    \n",
        "    mol = Chem.MolFromSmiles( smiles ) # no hydrogen \n",
        "    z = np.array( [atom.GetAtomicNum() for atom in mol.GetAtoms()] )\n",
        "    A = np.stack(Chem.GetAdjacencyMatrix(mol))\n",
        "    \n",
        "    return z, A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVSxuShzu27W"
      },
      "source": [
        "class GraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,\n",
        "                 AtomicNum_list, \n",
        "                 Edge_list, \n",
        "                 Natom_list, \n",
        "                 y_list):\n",
        "        \n",
        "        '''\n",
        "        GraphDataset object\n",
        "        \n",
        "        Args: \n",
        "            z_list (list of torch.LongTensor)\n",
        "            a_list (list of torch.LongTensor)\n",
        "            N_list (list of int)\n",
        "            y_list (list of torch.FloatTensor)\n",
        "\n",
        "        '''\n",
        "        self.AtomicNum_list = AtomicNum_list # atomic number\n",
        "        self.Edge_list = Edge_list # edge list \n",
        "        self.Natom_list = Natom_list # Number of atoms \n",
        "        self.y_list = y_list # properties to predict \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Natom_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        AtomicNum = torch.LongTensor(self.AtomicNum_list[idx])\n",
        "        Edge = torch.LongTensor(self.Edge_list[idx])\n",
        "        Natom = self.Natom_list[idx]\n",
        "        y = torch.Tensor(self.y_list[idx])\n",
        "        \n",
        "        return AtomicNum, Edge, Natom, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lPCLjWpu27X"
      },
      "source": [
        "def collate_graphs(batch):\n",
        "    '''Batch multiple graphs into one batched graph\n",
        "    \n",
        "    Args:\n",
        "    \n",
        "        batch (tuple): tuples of AtomicNum, Edge, Natom and y obtained from GraphDataset.__getitem__() \n",
        "        \n",
        "    Return \n",
        "        (tuple): Batched AtomicNum, Edge, Natom, y\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    AtomicNum_batch = []\n",
        "    Edge_batch = []\n",
        "    Natom_batch = []\n",
        "    y_batch = []\n",
        "\n",
        "    cumulative_atoms = np.cumsum([0] + [b[2] for b in batch])[:-1]\n",
        "    \n",
        "    for i in range(len(batch)):\n",
        "        z, a, N, y = batch[i]\n",
        "        index_shift = cumulative_atoms[i]\n",
        "        a = a + index_shift\n",
        "        AtomicNum_batch.append(z) \n",
        "        Edge_batch.append(a)\n",
        "        Natom_batch.append(N)\n",
        "        y_batch.append(y)\n",
        "        \n",
        "    AtomicNum_batch = torch.cat(AtomicNum_batch)\n",
        "    Edge_batch = torch.cat(Edge_batch, dim=1)\n",
        "    Natom_batch = Natom_batch\n",
        "    y_batch = torch.cat(y_batch)\n",
        "    \n",
        "    return AtomicNum_batch, Edge_batch, Natom_batch, y_batch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDVilSwqdVsI"
      },
      "source": [
        "# Example usage of collate_graph\n",
        "\n",
        "# define graph 1 \n",
        "AtomicNum1 = torch.LongTensor([6, 6, 7])\n",
        "Edge1 = torch.LongTensor([[0, 2, 2, 1], \n",
        "                       [2, 0, 1, 2]])\n",
        "Natom1 = 3\n",
        "y1 =  torch.Tensor([74.18])\n",
        "# define graph 2 \n",
        "AtomicNum2 = torch.LongTensor([6, 6, 8])\n",
        "Edge2 = torch.LongTensor([[0, 2, 2, 1], \n",
        "                       [2, 0, 1, 2]])\n",
        "Natom2 = 3\n",
        "y2 = torch.Tensor([64.32])\n",
        "\n",
        "graph1 = (AtomicNum1, Edge1, Natom1, y1)\n",
        "graph2 = (AtomicNum2, Edge2, Natom2, y2)\n",
        "\n",
        "collate_graphs((graph1, graph2))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f3sGR1XdVsJ"
      },
      "source": [
        "Make lists of data for molecular graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QplWbt60dVsJ"
      },
      "source": [
        "import torch\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df = pd.read_csv(\"qm9.csv\")\n",
        "df = shuffle(df).reset_index()\n",
        "\n",
        "################ Code #################\n",
        "\n",
        "AtomicNum_list = []\n",
        "Edge_list = []\n",
        "y_list = []\n",
        "Natom_list = []\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6uT_hHKdVsJ"
      },
      "source": [
        "Make train, valdiation, test datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvrFsZMnu27Y"
      },
      "source": [
        "################ Code #################\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pND0eELru27Y"
      },
      "source": [
        "### 1.3 Complete the definition of a GNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07W6nUPkdVsK"
      },
      "source": [
        "from itertools import repeat\n",
        "def scatter_add(src, index, dim_size, dim=-1, fill_value=0):\n",
        "    \n",
        "    '''\n",
        "    Sums all values from the src tensor into out at the indices specified in the index \n",
        "    tensor along a given axis dim. \n",
        "    '''\n",
        "    \n",
        "    index_size = list(repeat(1, src.dim()))\n",
        "    index_size[dim] = src.size(dim)\n",
        "    index = index.view(index_size).expand_as(src)\n",
        "    \n",
        "    dim = range(src.dim())[dim]\n",
        "    out_size = list(src.size())\n",
        "    out_size[dim] = dim_size\n",
        "\n",
        "    out = src.new_full(out_size, fill_value)\n",
        "\n",
        "    return out.scatter_add_(dim, index, src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqVacAGkdVsL"
      },
      "source": [
        "#### Example usage for scatter_add() and torch.split() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUBo2SLbdVsL"
      },
      "source": [
        "# scatter_add() example usage \n",
        "tensor = torch.ones(5, 2) # source array \n",
        "index = torch.LongTensor([0, 0, 2, 2, 1]) # index to be summed \n",
        "print(scatter_add(tensor, index, dim=0, dim_size=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkbEciNdVsL"
      },
      "source": [
        "# torch.split() example usage \n",
        "splits_idx = [2, 3] # list of integers \n",
        "print( torch.split(tensor, splits_idx) ) \n",
        "\n",
        "# you have two tensors with size (2,2) and (3,2) respectively \n",
        "for split in torch.split(tensor, splits_idx):\n",
        "    print(split.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNZxI5T9dVsM"
      },
      "source": [
        "# And you can sum the spllited array separately and stack them together \n",
        "print( torch.stack([split.sum(0) for split in torch.split(tensor, splits_idx)], dim=0) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xjflAkwu27Y"
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import ModuleDict\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    '''\n",
        "        A GNN model \n",
        "    '''\n",
        "    def __init__(self, n_convs=3, n_embed=64):\n",
        "        super(GNN, self).__init__()\n",
        "        \n",
        "        self.atom_embed = nn.Embedding(100, n_embed)\n",
        "        # Declare MLPs in a ModuleList\n",
        "        self.convolutions = nn.ModuleList(\n",
        "            [ \n",
        "                ModuleDict({\n",
        "                    'update_mlp': nn.Sequential(nn.Linear(n_embed, n_embed), \n",
        "                                                nn.ReLU(), \n",
        "                                                nn.Linear(n_embed, n_embed)),\n",
        "                    'message_mlp': nn.Sequential(nn.Linear(n_embed, n_embed), \n",
        "                                                 nn.ReLU(), \n",
        "                                                 nn.Linear(n_embed, n_embed)) \n",
        "                })\n",
        "                for _ in range(n_convs)\n",
        "            ]\n",
        "            )\n",
        "        # Declare readout layers\n",
        "        self.readout = nn.Sequential(nn.Linear(n_embed, n_embed), nn.ReLU(), nn.Linear(n_embed, 1))\n",
        "        \n",
        "    def forward(self, AtomicNum, Edge, Natom):\n",
        "        ################ Code #################\n",
        "        \n",
        "        # Parametrize embedding \n",
        "        h = self.atom_embed(AtomicNum) #eqn. 1\n",
        "        \n",
        "        for conv in self.convolutions:\n",
        "        \n",
        "    \n",
        "        \n",
        "        ################ Code #################\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmypwqSlu27Z"
      },
      "source": [
        "### 1.4 Verify that your GNN preserves permutational invariance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F7-dv8su27Z"
      },
      "source": [
        "def permute_graph(z, a, perm):\n",
        "    '''\n",
        "        permute the order of nodes in a molecular graph \n",
        "        \n",
        "        Args: \n",
        "            z(np.array): atomic number array\n",
        "            a(np.array): edge index pairs \n",
        "            \n",
        "        Return: \n",
        "            (np.array, np.array): permuted atomic number, and edge list \n",
        "    '''\n",
        "    \n",
        "    z = np.array(z)\n",
        "    perm = np.array(perm)\n",
        "    assert len(perm) == len(z)\n",
        "    \n",
        "    z_perm = z[perm]\n",
        "    a_perm = np.zeros(a.shape).astype(int)\n",
        "    \n",
        "    for i, edge in enumerate(a):\n",
        "        for j in range(len(edge)):\n",
        "            a_perm[i, j] = np.where(perm==edge[j])[0]\n",
        "    return z_perm, a_perm\n",
        "\n",
        "# node input\n",
        "AtomicNum_orig = np.array([6, 6, 8, 7])\n",
        "# edge input \n",
        "Edge_orig = np.array([[0, 0, 1, 2, 3, 0], [1, 2, 0, 0, 0, 3]] )\n",
        "# generate permutations\n",
        "permutation = itertools.permutations([0, 1 ,2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bulr_8wadVsN"
      },
      "source": [
        "Test your model on permuted graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t0AE5KndVsN"
      },
      "source": [
        "################ Code #################\n",
        "\n",
        "device = 0\n",
        "model = GNN(n_convs=4, n_embed=128).to(device)\n",
        "model.eval()\n",
        "\n",
        "for perm in permutation:\n",
        "    print(\"model output: {:.5f} for perumutation: {}\".format(output, perm)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5KEswY8u27a"
      },
      "source": [
        "### 1.5  Train and test your GNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8DqTDDbu27a"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMgcJzzzu27a"
      },
      "source": [
        "def loop(model, loader, epoch, evaluation=False):\n",
        "    \n",
        "    if evaluation:\n",
        "        model.eval()\n",
        "        mode = \"eval\"\n",
        "    else:\n",
        "        model.train()\n",
        "        mode = 'train'\n",
        "    batch_losses = []\n",
        "    \n",
        "    # Define tqdm progress bar \n",
        "    tqdm_data = tqdm(loader, position=0, leave=True, desc='{} (epoch #{})'.format(mode, epoch))\n",
        "    \n",
        "    for data in tqdm_data:\n",
        "        \n",
        "        AtomicNumber, Edge, Natom, y = data \n",
        "        AtomicNumber = AtomicNumber.to(device)\n",
        "        Edge = Edge.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        # make predictions \n",
        "        pred = model(AtomicNumber, Edge, Natom)\n",
        "        \n",
        "        # define loss \n",
        "        loss = (pred-y).pow(2).mean()  \n",
        "        \n",
        "        if not evaluation:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "        postfix = ['batch loss={:.3f}'.format(loss.item()) , \n",
        "                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n",
        "        \n",
        "        tqdm_data.set_postfix_str(' '.join(postfix))\n",
        "    \n",
        "    return np.array(batch_losses).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rjYSawwu27a"
      },
      "source": [
        "for epoch in range(500):    \n",
        "    train_loss = loop(model, train_loader, epoch)\n",
        "    val_loss = loop(model, val_loader, epoch, evaluation=True)\n",
        "    \n",
        "    # save model \n",
        "    if epoch % 20 == 0:\n",
        "        torch.save(model.state_dict(), \"{}/gcn_model_{}.pt\".format(mydrive, epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEPUcAOndePL"
      },
      "source": [
        "Scatter plots and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNEpmwLNdXjq"
      },
      "source": [
        "################ Code #################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}