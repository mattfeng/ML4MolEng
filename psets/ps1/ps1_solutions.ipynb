{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center> Problem Set 1 <center>\n",
    "<center> Spring 2021 <center>\n",
    "<center> 3.100/3.322, 10.402/10.602, 20.301/20.401 <center>\n",
    "<center> Due:10 pm ET on Thursday, March 4, 2021 <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Your name\n",
    "\n",
    "kerberos id: Your kerberos id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instructions: \n",
    "\n",
    "Put your code in the code block like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### ùô≤ùöòùöçùöé #############  \n",
    "def mycode():\n",
    "    print(\"run my code here\")\n",
    "    \n",
    "def plot():\n",
    "    plt.hist(np.ones(100))\n",
    "\n",
    "mycode()\n",
    "plot()\n",
    "########### ùô≤ùöòùöçùöé ############# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provided print statements where numerical answers are expected. \n",
    "\n",
    "Your answer should be contained in a variable which you defined either in the Answer Block or the Code Block.\n",
    "\n",
    "When a qualitative answer is expected. You can write answer as code comments by placing a # before your answer \n",
    "\n",
    "Your Answer Block should look like the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############ + $\n",
    "\n",
    "ans = 2\n",
    "print(\"My answer is: {}.\".format(ans))\n",
    "\n",
    "# My regressor over-fitted the training data, I need to add regularization + $\n",
    "\n",
    "########## Answer ############ + $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics \n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting style, you can choose your own parameters\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rc('lines', linewidth=3, color='g')\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams[\"xtick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 2\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 2\n",
    "matplotlib.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for students to produce plots \n",
    "def plot_clf(model, X, y, title): \n",
    "    \n",
    "    '''\n",
    "        A function to plot confusion matrix and ROC curve \n",
    "        \n",
    "        Args: \n",
    "            model(classifier object): model object (e.g. RandomForestClassifier, LogisticRegression)\n",
    "            X(np.array): feature set\n",
    "            y(np.array): label set \n",
    "            title(str): plot name\n",
    "            \n",
    "        Example Usage: \n",
    "            plot_clf(model, X_test, y_test, \"test\")\n",
    "    '''\n",
    "    \n",
    "    fig, [ax_roc, ax_conf] = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plot_roc_curve(model, X, y, ax=ax_roc)\n",
    "    plot_confusion_matrix(model, X, y, ax=ax_conf)\n",
    "\n",
    "    ax_roc.set_title('{} ROC'.format(title))\n",
    "    ax_conf.set_title('{} Confusion Mat.'.format(title))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Problem 1 <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data \n",
    "\n",
    "!wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps1/data/breastcancer_X.csv\n",
    "!wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps1/data/breastcancer_y.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provided the code to load the dataset. Take a moment to understand what each line is doing. Briefy explain what each line of the code is doing by providing short comments below. \n",
    "\n",
    "You will have to do it by yourself again in Problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"./breastcancer_X.csv\", header='infer', index_col=0) # Comments here \n",
    "y = pd.read_csv(\"./breastcancer_y.csv\", header='infer', index_col=0) # Comments here \n",
    "\n",
    "metabolite_name = X.columns.tolist() # Comments here \n",
    "\n",
    "X = X.values # Comments here \n",
    "y = y.values # Comments here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report how many examples are in this datasetand the number of features for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"There are {} samples.\".format(N_samples))\n",
    "print(\"There are {} features per sample.\".format(N_features))\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to split dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the shapes of your four variables, Xtrain, Xtest, ytrain, and ytest, and ensure sure that the dimensions match your expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "\n",
    "print(\"Xtrain shape: {}\".format(Xtrain_shape))\n",
    "print(\"ytrain shape: {}\".format(ytrain_shape))\n",
    "\n",
    "print(\"Xtest shape: {}\".format(Xtest_shape))\n",
    "print(\"ytest shape: {}\".format(ytest_shape))\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to Scale the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the mean/variance for each transformed feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "mean = np.zeros(10)\n",
    "variance = np.zeros(10)\n",
    "\n",
    "print(\"The means of the transformed feature set are {}\".format(mean) )\n",
    "print(\"The variances of the transformed feature set are {}\".format(variance) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and evaluate a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report the AUC scorefor both training and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "train_auc = 0.5\n",
    "test_auc = 0.5\n",
    "print(\"The training AUC score is {}\".format(train_auc) )\n",
    "print(\"The testing AUC score is {}\".format(test_auc) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate plots for confusion matrices and ROCcurve for both training and testing. Please use the plot_clf function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to perform cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report the cross validated ROC-AUC score in terms of its mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The mean of CV scores is {}\".format(mean) )\n",
    "print(\"The std of CV scores is {}\".format(std) )\n",
    "\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6  (Extra credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to identify the top 5 metabolites that positively correlated the most with positive diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the metabolites you identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "metboliates = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "print(\"The top 5 metabolites are {}\".format(\", \".join(metboliates)) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each hypothetical featurization, obtain an average ROC-AUC and its standard deviation through a 5-fold CV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use matplotlib to generate one scatter showing these cross-validated test AUC score (y-axis) as a function of the different different feature subset sizes (x-axis) with error bars corresponding to the standard deviations. Here, we provide an example plotting code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "# generate random data \n",
    "feature_sizes = [0.2, 0.4, 0.6, 0.8]\n",
    "y_auc = np.random.randn(4)\n",
    "y_uncer = np.random.uniform(0.2, 1, size=4) * 0.25\n",
    "\n",
    "# plotting code \n",
    "plt.figure(figsize=(5,5)) # define figure size \n",
    "plt.errorbar(feature_sizes, y_auc, y_uncer, marker='o', ms=10, mew=2, label='line 1') \n",
    "plt.xlabel('feature sizes')\n",
    "plt.ylabel('CV-AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps1/data/liver_X.csv\n",
    "!wget https://raw.githubusercontent.com/wwang2/ML4MolEng/master/psets/ps1/data/liver_y.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow  the  same  procedure  from  Part  1  to  load  the  data,  split  the  data,  scale  the  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train  a logistic  regression  model,  and  test  its  performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Confusion Matrix and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report your test ROC-AUC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The training AUC score is {}\".format(train_auc) )\n",
    "print(\"The testing AUC score is {}\".format(test_auc) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run L1-regularized Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report ROC-AUC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The training AUC score is {}\".format(train_auc) )\n",
    "print(\"The testing AUC score is {}\".format(test_auc) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Confusion Matrix and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the histrogram of model coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the histogram you obtained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run L2-regularized Logistic Regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Confusion Matrix and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report test ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The training AUC score is {}\".format(train_auc) )\n",
    "print(\"The testing AUC score is {}\".format(test_auc) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the histrogram of model coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment on your histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run un-regularized and L1-regularized logistic regressions for the fol-lowing random train/test splits:\n",
    "\n",
    "{20%/30%,30%/30%,40%/30%,50%/30%,60%/30%}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training/testing ROC-AUC score as a function of train size for L1-regularized and un-regularized regressions. We provided example plotting code with random data, you can use it as a template to generate two plots: one for the L1-regularized regression, and one for the un-regularized regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "# generate random data \n",
    "train_sizes = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "y_auc = np.random.randn(5)\n",
    "y_uncer = np.random.uniform(0.2, 1, size=5)\n",
    "\n",
    "# Define plots \n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "# first plot\n",
    "plt.errorbar(train_sizes, y_auc, y_uncer,\n",
    "             marker='o', color='blue', linestyle='--',\n",
    "             ms=10, mew=2, label='L1 train')\n",
    "\n",
    "# 2nd plot\n",
    "plt.errorbar(train_sizes, y_auc + 2, y_uncer, \n",
    "             marker='o', color='orange',  ms=10, linestyle='-', \n",
    "             mew=2, label='L1 test') # plotting for test score\n",
    "\n",
    "plt.xlabel('train sizes')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment  on  when  the  model  is  most  prone  to  poor generalization (i.e., a large gap between training and testing performance):  with or without regularization?  For large or small training set sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run crossvalidation for a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the cross-validated ROC-AUC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The mean of CV scores is {}\".format(mean) )\n",
    "print(\"The std of CV scores is {}\".format(std) )\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [40, 80, 160, 320, 640, 1280], \n",
    "              'min_samples_split': [8, 10, 12, 24], \n",
    "              'max_depth': [2, 4, 8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the total number of possible parameter combinations given the parameter ranges given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"There are {} different combinations\".format(N_comb))\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the provided parameter set to run Grid Hyperparameter Search with Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the obtained parameter set. Answer in code comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "# The optimized parameter set is:\n",
    "# {\n",
    "#    'n_estimators': #answer,  \n",
    "#    'min_samples_split': #answer,\n",
    "#    'max_depth': #answer\n",
    "# }\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the best cross-validation score from your Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The best cross-validated AUC score is {}\".format(cv_auc))\n",
    "\n",
    "########## Answer ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate on the validation( held-out) data with your best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Code #############\n",
    "\n",
    "\n",
    "\n",
    "########### Code #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report AUC score on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Answer ############\n",
    "\n",
    "print(\"The validation AUC score calculated with the best model is {}\".format(val_auc))\n",
    "\n",
    "########## Answer ############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:htvs3.8]",
   "language": "python",
   "name": "conda-env-htvs3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
